{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "OpenSourceToneAnalyser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWCompMLE674"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-KXbLSDU3cc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount']\n",
        "data_positive = pd.read_csv('/content/drive/MyDrive/data/positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
        "data_negative = pd.read_csv('/content/drive/MyDrive/data/negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
        "\n",
        "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
        "raw_data = np.concatenate((data_positive['text'].values[:sample_size],\n",
        "                           data_negative['text'].values[:sample_size]), axis=0)\n",
        "labels = [1] * sample_size + [0] * sample_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTfgccK_W0DR",
        "outputId": "e1ccc3a0-4cbb-42f6-b107-fa714fc0a082"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQRPoRytU3ce"
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower().replace(\"ё\", \"е\")\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
        "    text = re.sub('@[^\\s]+', 'USER', text)\n",
        "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "data = [preprocess_text(t) for t in raw_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IDg_BGpU3cf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CkGPQ_fU3ci"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR34E4NfU3cl"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "SENTENCE_LENGTH = 26\n",
        "NUM = 100000\n",
        "\n",
        "def get_sequences(tokenizer, x):\n",
        "    sequences = tokenizer.texts_to_sequences(x)\n",
        "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "x_train_seq = get_sequences(tokenizer, x_train)\n",
        "x_test_seq = get_sequences(tokenizer, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUTJVYAcU3cm"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "# Загружаем обученную модель\n",
        "w2v_model = Word2Vec.load('/content/drive/MyDrive/models/w2v/tweets_model.w2v')\n",
        "DIM = w2v_model.vector_size \n",
        "# Инициализируем матрицу embedding слоя нулями\n",
        "embedding_matrix = np.zeros((NUM, DIM))\n",
        "# Добавляем NUM=100000 наиболее часто встречающихся слов из обучающей выборки в embedding слой\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= NUM:\n",
        "        break\n",
        "    if word in w2v_model.wv.vocab.keys():\n",
        "        embedding_matrix[i] = w2v_model.wv[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5q0akcZU3cn"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "tweet_input = Input(shape=(SENTENCE_LENGTH,), dtype='int32')\n",
        "tweet_encoder = Embedding(NUM, DIM, input_length=SENTENCE_LENGTH,\n",
        "                          weights=[embedding_matrix], trainable=False)(tweet_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZg8WdVCU3co",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30bae5df-d488-41aa-9cfb-d8765d9a81d9"
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.layers import Dense, concatenate, Activation, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "\n",
        "branches = []\n",
        "x = Dropout(0.2)(tweet_encoder)\n",
        "\n",
        "for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]:\n",
        "    for i in range(filters_count):\n",
        "        branch = Conv1D(filters=1, kernel_size=size, padding='valid', activation='relu')(x)\n",
        "        branch = GlobalMaxPooling1D()(branch)\n",
        "        branches.append(branch)\n",
        "\n",
        "x = concatenate(branches, axis=1)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(30, activation='relu')(x)\n",
        "x = Dense(1)(x)\n",
        "output = Activation('sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=[tweet_input], outputs=[output])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision, recall, f1])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 26)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 26, 200)      20000000    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 26, 200)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_80 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_81 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_82 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_83 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_84 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_85 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_86 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_87 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_88 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_89 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_90 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_91 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_92 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_93 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_94 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_95 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_96 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_97 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_98 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_99 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_100 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_101 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_102 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_103 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_104 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_108 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_109 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_110 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_111 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_112 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_113 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_114 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_115 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_116 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_117 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_118 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_119 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_80 (Global (None, 1)            0           conv1d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_81 (Global (None, 1)            0           conv1d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_82 (Global (None, 1)            0           conv1d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_83 (Global (None, 1)            0           conv1d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_84 (Global (None, 1)            0           conv1d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_85 (Global (None, 1)            0           conv1d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_86 (Global (None, 1)            0           conv1d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_87 (Global (None, 1)            0           conv1d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_88 (Global (None, 1)            0           conv1d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_89 (Global (None, 1)            0           conv1d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_90 (Global (None, 1)            0           conv1d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_91 (Global (None, 1)            0           conv1d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_92 (Global (None, 1)            0           conv1d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_93 (Global (None, 1)            0           conv1d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_94 (Global (None, 1)            0           conv1d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_95 (Global (None, 1)            0           conv1d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_96 (Global (None, 1)            0           conv1d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_97 (Global (None, 1)            0           conv1d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_98 (Global (None, 1)            0           conv1d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_99 (Global (None, 1)            0           conv1d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_100 (Globa (None, 1)            0           conv1d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_101 (Globa (None, 1)            0           conv1d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_102 (Globa (None, 1)            0           conv1d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_103 (Globa (None, 1)            0           conv1d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_104 (Globa (None, 1)            0           conv1d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_105 (Globa (None, 1)            0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_106 (Globa (None, 1)            0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_107 (Globa (None, 1)            0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_108 (Globa (None, 1)            0           conv1d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_109 (Globa (None, 1)            0           conv1d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_110 (Globa (None, 1)            0           conv1d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_111 (Globa (None, 1)            0           conv1d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_112 (Globa (None, 1)            0           conv1d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_113 (Globa (None, 1)            0           conv1d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_114 (Globa (None, 1)            0           conv1d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_115 (Globa (None, 1)            0           conv1d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_116 (Globa (None, 1)            0           conv1d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_117 (Globa (None, 1)            0           conv1d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_118 (Globa (None, 1)            0           conv1d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_119 (Globa (None, 1)            0           conv1d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 40)           0           global_max_pooling1d_80[0][0]    \n",
            "                                                                 global_max_pooling1d_81[0][0]    \n",
            "                                                                 global_max_pooling1d_82[0][0]    \n",
            "                                                                 global_max_pooling1d_83[0][0]    \n",
            "                                                                 global_max_pooling1d_84[0][0]    \n",
            "                                                                 global_max_pooling1d_85[0][0]    \n",
            "                                                                 global_max_pooling1d_86[0][0]    \n",
            "                                                                 global_max_pooling1d_87[0][0]    \n",
            "                                                                 global_max_pooling1d_88[0][0]    \n",
            "                                                                 global_max_pooling1d_89[0][0]    \n",
            "                                                                 global_max_pooling1d_90[0][0]    \n",
            "                                                                 global_max_pooling1d_91[0][0]    \n",
            "                                                                 global_max_pooling1d_92[0][0]    \n",
            "                                                                 global_max_pooling1d_93[0][0]    \n",
            "                                                                 global_max_pooling1d_94[0][0]    \n",
            "                                                                 global_max_pooling1d_95[0][0]    \n",
            "                                                                 global_max_pooling1d_96[0][0]    \n",
            "                                                                 global_max_pooling1d_97[0][0]    \n",
            "                                                                 global_max_pooling1d_98[0][0]    \n",
            "                                                                 global_max_pooling1d_99[0][0]    \n",
            "                                                                 global_max_pooling1d_100[0][0]   \n",
            "                                                                 global_max_pooling1d_101[0][0]   \n",
            "                                                                 global_max_pooling1d_102[0][0]   \n",
            "                                                                 global_max_pooling1d_103[0][0]   \n",
            "                                                                 global_max_pooling1d_104[0][0]   \n",
            "                                                                 global_max_pooling1d_105[0][0]   \n",
            "                                                                 global_max_pooling1d_106[0][0]   \n",
            "                                                                 global_max_pooling1d_107[0][0]   \n",
            "                                                                 global_max_pooling1d_108[0][0]   \n",
            "                                                                 global_max_pooling1d_109[0][0]   \n",
            "                                                                 global_max_pooling1d_110[0][0]   \n",
            "                                                                 global_max_pooling1d_111[0][0]   \n",
            "                                                                 global_max_pooling1d_112[0][0]   \n",
            "                                                                 global_max_pooling1d_113[0][0]   \n",
            "                                                                 global_max_pooling1d_114[0][0]   \n",
            "                                                                 global_max_pooling1d_115[0][0]   \n",
            "                                                                 global_max_pooling1d_116[0][0]   \n",
            "                                                                 global_max_pooling1d_117[0][0]   \n",
            "                                                                 global_max_pooling1d_118[0][0]   \n",
            "                                                                 global_max_pooling1d_119[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 40)           0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 30)           1230        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            31          dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1)            0           dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 20,029,301\n",
            "Trainable params: 29,301\n",
            "Non-trainable params: 20,000,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAJSEGuDU3cq"
      },
      "source": [
        "## 5. Training and evaluating the CNN\n",
        "\n",
        "The dataset was divided into three parts: train dataset (60% of the entire dataset), validation dataset (20% of the entire dataset), and test dataset (20% of the entire dataset). The loss function was minimized using the Adam optimizer with a learning rate of 0.001. The embedding layer, which was initialized with Word2Vec word embeddings, was frozen for the first 10 epochs. Then we train model from the previous step with best validation scores for additional 5 epochs with unfrozen embeddings and a learning rate of 0.0001. The best results in terms of F-measure was 77.67%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCAuCluHjlmm"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3r6y4oilUJa",
        "outputId": "616acce5-b65c-4722-96af-4f35628521f4"
      },
      "source": [
        "try:\n",
        "  import tensorflow.compat.v2 as tf\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmuxa8yRlgjo",
        "outputId": "37bf1591-45ea-4441-9c5e-afb20d27d72c"
      },
      "source": [
        "!tf_upgrade_v2 -h\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: tf_upgrade_v2 [-h] [--infile INPUT_FILE] [--outfile OUTPUT_FILE]\n",
            "                     [--intree INPUT_TREE] [--outtree OUTPUT_TREE]\n",
            "                     [--copyotherfiles COPY_OTHER_FILES] [--inplace]\n",
            "                     [--import_rename] [--reportfile REPORT_FILENAME]\n",
            "                     [--mode {DEFAULT,SAFETY}] [--print_all]\n",
            "\n",
            "Convert a TensorFlow Python file from 1.x to 2.0\n",
            "\n",
            "Simple usage:\n",
            "  tf_upgrade_v2.py --infile foo.py --outfile bar.py\n",
            "  tf_upgrade_v2.py --infile foo.ipynb --outfile bar.ipynb\n",
            "  tf_upgrade_v2.py --intree ~/code/old --outtree ~/code/new\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --infile INPUT_FILE   If converting a single file, the name of the file to\n",
            "                        convert\n",
            "  --outfile OUTPUT_FILE\n",
            "                        If converting a single file, the output filename.\n",
            "  --intree INPUT_TREE   If converting a whole tree of files, the directory to\n",
            "                        read from (relative or absolute).\n",
            "  --outtree OUTPUT_TREE\n",
            "                        If converting a whole tree of files, the output\n",
            "                        directory (relative or absolute).\n",
            "  --copyotherfiles COPY_OTHER_FILES\n",
            "                        If converting a whole tree of files, whether to copy\n",
            "                        the other files.\n",
            "  --inplace             If converting a set of files, whether to allow the\n",
            "                        conversion to be performed on the input files.\n",
            "  --import_rename       Whether to rename import to compact.v2 explicitly.\n",
            "  --reportfile REPORT_FILENAME\n",
            "                        The name of the file where the report log is\n",
            "                        stored.(default: report.txt)\n",
            "  --mode {DEFAULT,SAFETY}\n",
            "                        Upgrade script mode. Supported modes: DEFAULT: Perform\n",
            "                        only straightforward conversions to upgrade to 2.0. In\n",
            "                        more difficult cases, switch to use compat.v1. SAFETY:\n",
            "                        Keep 1.* code intact and import compat.v1 module.\n",
            "  --print_all           Print full log to stdout instead of just printing\n",
            "                        errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzJG3fX6U3cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7edfe6ea-aa5f-45b4-87a2-cc01a05bea47"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/models/cnn/cnn-frozen-embeddings-09-0.77.hdf5\", \n",
        "                             monitor='val_f1', save_best_only=True, mode='max', save_freq = 10)\n",
        "\n",
        "\n",
        "x_train_seq = np.asarray(x_train_seq)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "\n",
        "history = model.fit(x=x_train_seq, y=y_train, batch_size=32, validation_split=0.25, callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  10/4198 [..............................] - ETA: 7:12 - loss: 1.2062 - precision: 0.3860 - recall: 0.3908 - f1: 0.3730WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  20/4198 [..............................] - ETA: 7:03 - loss: 1.1209 - precision: 0.4186 - recall: 0.3620 - f1: 0.3718WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  30/4198 [..............................] - ETA: 6:58 - loss: 1.0553 - precision: 0.4437 - recall: 0.4321 - f1: 0.4209WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  40/4198 [..............................] - ETA: 6:56 - loss: 1.0072 - precision: 0.4558 - recall: 0.4408 - f1: 0.4243WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  50/4198 [..............................] - ETA: 6:57 - loss: 0.9645 - precision: 0.4616 - recall: 0.4219 - f1: 0.4178WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  60/4198 [..............................] - ETA: 6:57 - loss: 0.9267 - precision: 0.4796 - recall: 0.4617 - f1: 0.4495WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  70/4198 [..............................] - ETA: 6:56 - loss: 0.8983 - precision: 0.5016 - recall: 0.4868 - f1: 0.4752WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  80/4198 [..............................] - ETA: 6:56 - loss: 0.8734 - precision: 0.5204 - recall: 0.5077 - f1: 0.4967WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "  90/4198 [..............................] - ETA: 6:56 - loss: 0.8650 - precision: 0.5229 - recall: 0.5366 - f1: 0.5113WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 100/4198 [..............................] - ETA: 6:56 - loss: 0.8475 - precision: 0.5247 - recall: 0.5469 - f1: 0.5175WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 110/4198 [..............................] - ETA: 6:55 - loss: 0.8405 - precision: 0.5259 - recall: 0.5361 - f1: 0.5132WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 120/4198 [..............................] - ETA: 6:53 - loss: 0.8302 - precision: 0.5294 - recall: 0.5348 - f1: 0.5152WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 130/4198 [..............................] - ETA: 6:52 - loss: 0.8234 - precision: 0.5294 - recall: 0.5351 - f1: 0.5163WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 140/4198 [>.............................] - ETA: 6:50 - loss: 0.8147 - precision: 0.5310 - recall: 0.5374 - f1: 0.5186WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 150/4198 [>.............................] - ETA: 6:49 - loss: 0.8043 - precision: 0.5367 - recall: 0.5419 - f1: 0.5244WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 160/4198 [>.............................] - ETA: 6:47 - loss: 0.7970 - precision: 0.5386 - recall: 0.5433 - f1: 0.5267WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 170/4198 [>.............................] - ETA: 6:46 - loss: 0.7904 - precision: 0.5401 - recall: 0.5447 - f1: 0.5288WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 180/4198 [>.............................] - ETA: 6:44 - loss: 0.7846 - precision: 0.5436 - recall: 0.5502 - f1: 0.5337WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 190/4198 [>.............................] - ETA: 6:42 - loss: 0.7808 - precision: 0.5438 - recall: 0.5493 - f1: 0.5338WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 200/4198 [>.............................] - ETA: 6:40 - loss: 0.7778 - precision: 0.5436 - recall: 0.5467 - f1: 0.5328WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 210/4198 [>.............................] - ETA: 6:39 - loss: 0.7730 - precision: 0.5473 - recall: 0.5490 - f1: 0.5362WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 220/4198 [>.............................] - ETA: 6:37 - loss: 0.7686 - precision: 0.5470 - recall: 0.5512 - f1: 0.5371WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 230/4198 [>.............................] - ETA: 6:36 - loss: 0.7640 - precision: 0.5488 - recall: 0.5542 - f1: 0.5395WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 240/4198 [>.............................] - ETA: 6:34 - loss: 0.7609 - precision: 0.5512 - recall: 0.5521 - f1: 0.5396WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 250/4198 [>.............................] - ETA: 6:33 - loss: 0.7567 - precision: 0.5548 - recall: 0.5555 - f1: 0.5433WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 260/4198 [>.............................] - ETA: 6:31 - loss: 0.7522 - precision: 0.5590 - recall: 0.5629 - f1: 0.5493WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 270/4198 [>.............................] - ETA: 6:30 - loss: 0.7500 - precision: 0.5581 - recall: 0.5667 - f1: 0.5506WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 280/4198 [=>............................] - ETA: 6:29 - loss: 0.7477 - precision: 0.5588 - recall: 0.5643 - f1: 0.5497WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 290/4198 [=>............................] - ETA: 6:28 - loss: 0.7457 - precision: 0.5619 - recall: 0.5638 - f1: 0.5506WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 300/4198 [=>............................] - ETA: 6:27 - loss: 0.7440 - precision: 0.5607 - recall: 0.5669 - f1: 0.5516WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 310/4198 [=>............................] - ETA: 6:26 - loss: 0.7417 - precision: 0.5626 - recall: 0.5697 - f1: 0.5540WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 320/4198 [=>............................] - ETA: 6:25 - loss: 0.7386 - precision: 0.5635 - recall: 0.5693 - f1: 0.5541WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 330/4198 [=>............................] - ETA: 6:24 - loss: 0.7362 - precision: 0.5649 - recall: 0.5695 - f1: 0.5550WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 340/4198 [=>............................] - ETA: 6:23 - loss: 0.7333 - precision: 0.5674 - recall: 0.5713 - f1: 0.5574WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 350/4198 [=>............................] - ETA: 6:22 - loss: 0.7312 - precision: 0.5701 - recall: 0.5740 - f1: 0.5602WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 360/4198 [=>............................] - ETA: 6:21 - loss: 0.7292 - precision: 0.5715 - recall: 0.5775 - f1: 0.5627WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 370/4198 [=>............................] - ETA: 6:20 - loss: 0.7281 - precision: 0.5704 - recall: 0.5784 - f1: 0.5625WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 380/4198 [=>............................] - ETA: 6:19 - loss: 0.7261 - precision: 0.5719 - recall: 0.5769 - f1: 0.5625WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 390/4198 [=>............................] - ETA: 6:18 - loss: 0.7247 - precision: 0.5725 - recall: 0.5778 - f1: 0.5631WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 400/4198 [=>............................] - ETA: 6:17 - loss: 0.7237 - precision: 0.5731 - recall: 0.5758 - f1: 0.5624WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 410/4198 [=>............................] - ETA: 6:16 - loss: 0.7220 - precision: 0.5742 - recall: 0.5762 - f1: 0.5631WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 420/4198 [==>...........................] - ETA: 6:15 - loss: 0.7196 - precision: 0.5765 - recall: 0.5778 - f1: 0.5651WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 430/4198 [==>...........................] - ETA: 6:13 - loss: 0.7182 - precision: 0.5772 - recall: 0.5809 - f1: 0.5671WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 440/4198 [==>...........................] - ETA: 6:12 - loss: 0.7165 - precision: 0.5778 - recall: 0.5820 - f1: 0.5679WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 450/4198 [==>...........................] - ETA: 6:11 - loss: 0.7147 - precision: 0.5791 - recall: 0.5824 - f1: 0.5689WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 460/4198 [==>...........................] - ETA: 6:10 - loss: 0.7125 - precision: 0.5803 - recall: 0.5843 - f1: 0.5703WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 470/4198 [==>...........................] - ETA: 6:09 - loss: 0.7106 - precision: 0.5823 - recall: 0.5850 - f1: 0.5717WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 480/4198 [==>...........................] - ETA: 6:08 - loss: 0.7087 - precision: 0.5837 - recall: 0.5864 - f1: 0.5732WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 490/4198 [==>...........................] - ETA: 6:07 - loss: 0.7076 - precision: 0.5844 - recall: 0.5896 - f1: 0.5753WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 500/4198 [==>...........................] - ETA: 6:06 - loss: 0.7062 - precision: 0.5849 - recall: 0.5905 - f1: 0.5761WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 510/4198 [==>...........................] - ETA: 6:05 - loss: 0.7038 - precision: 0.5867 - recall: 0.5901 - f1: 0.5766WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 520/4198 [==>...........................] - ETA: 6:04 - loss: 0.7030 - precision: 0.5874 - recall: 0.5903 - f1: 0.5771WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 530/4198 [==>...........................] - ETA: 6:03 - loss: 0.7013 - precision: 0.5887 - recall: 0.5936 - f1: 0.5794WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 540/4198 [==>...........................] - ETA: 6:02 - loss: 0.6998 - precision: 0.5899 - recall: 0.5961 - f1: 0.5814WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 550/4198 [==>...........................] - ETA: 6:01 - loss: 0.6987 - precision: 0.5912 - recall: 0.5976 - f1: 0.5828WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 560/4198 [===>..........................] - ETA: 6:00 - loss: 0.6970 - precision: 0.5913 - recall: 0.5970 - f1: 0.5826WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 570/4198 [===>..........................] - ETA: 5:59 - loss: 0.6952 - precision: 0.5936 - recall: 0.5966 - f1: 0.5835WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 580/4198 [===>..........................] - ETA: 5:58 - loss: 0.6940 - precision: 0.5955 - recall: 0.5983 - f1: 0.5854WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 590/4198 [===>..........................] - ETA: 5:57 - loss: 0.6929 - precision: 0.5961 - recall: 0.6015 - f1: 0.5873WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 600/4198 [===>..........................] - ETA: 5:56 - loss: 0.6911 - precision: 0.5973 - recall: 0.6017 - f1: 0.5881WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 610/4198 [===>..........................] - ETA: 5:55 - loss: 0.6892 - precision: 0.5985 - recall: 0.6019 - f1: 0.5889WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 620/4198 [===>..........................] - ETA: 5:54 - loss: 0.6878 - precision: 0.5989 - recall: 0.6019 - f1: 0.5891WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 630/4198 [===>..........................] - ETA: 5:52 - loss: 0.6869 - precision: 0.6001 - recall: 0.6031 - f1: 0.5904WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 640/4198 [===>..........................] - ETA: 5:52 - loss: 0.6855 - precision: 0.6003 - recall: 0.6057 - f1: 0.5917WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 650/4198 [===>..........................] - ETA: 5:51 - loss: 0.6841 - precision: 0.6006 - recall: 0.6056 - f1: 0.5919WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 660/4198 [===>..........................] - ETA: 5:50 - loss: 0.6828 - precision: 0.6025 - recall: 0.6058 - f1: 0.5928WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 670/4198 [===>..........................] - ETA: 5:49 - loss: 0.6809 - precision: 0.6043 - recall: 0.6076 - f1: 0.5948WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 680/4198 [===>..........................] - ETA: 5:48 - loss: 0.6799 - precision: 0.6047 - recall: 0.6102 - f1: 0.5962WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 690/4198 [===>..........................] - ETA: 5:47 - loss: 0.6789 - precision: 0.6056 - recall: 0.6096 - f1: 0.5964WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 700/4198 [====>.........................] - ETA: 5:46 - loss: 0.6783 - precision: 0.6068 - recall: 0.6101 - f1: 0.5972WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 710/4198 [====>.........................] - ETA: 5:45 - loss: 0.6775 - precision: 0.6068 - recall: 0.6126 - f1: 0.5983WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 720/4198 [====>.........................] - ETA: 5:44 - loss: 0.6765 - precision: 0.6075 - recall: 0.6143 - f1: 0.5996WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 730/4198 [====>.........................] - ETA: 5:43 - loss: 0.6757 - precision: 0.6086 - recall: 0.6146 - f1: 0.6003WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 740/4198 [====>.........................] - ETA: 5:42 - loss: 0.6746 - precision: 0.6097 - recall: 0.6157 - f1: 0.6015WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 750/4198 [====>.........................] - ETA: 5:41 - loss: 0.6735 - precision: 0.6108 - recall: 0.6163 - f1: 0.6024WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 760/4198 [====>.........................] - ETA: 5:40 - loss: 0.6725 - precision: 0.6111 - recall: 0.6167 - f1: 0.6029WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 770/4198 [====>.........................] - ETA: 5:39 - loss: 0.6722 - precision: 0.6114 - recall: 0.6171 - f1: 0.6032WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 780/4198 [====>.........................] - ETA: 5:38 - loss: 0.6715 - precision: 0.6110 - recall: 0.6163 - f1: 0.6027WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 790/4198 [====>.........................] - ETA: 5:37 - loss: 0.6704 - precision: 0.6115 - recall: 0.6164 - f1: 0.6030WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 800/4198 [====>.........................] - ETA: 5:36 - loss: 0.6693 - precision: 0.6125 - recall: 0.6166 - f1: 0.6037WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 810/4198 [====>.........................] - ETA: 5:35 - loss: 0.6676 - precision: 0.6140 - recall: 0.6176 - f1: 0.6050WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 820/4198 [====>.........................] - ETA: 5:34 - loss: 0.6668 - precision: 0.6139 - recall: 0.6184 - f1: 0.6053WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 830/4198 [====>.........................] - ETA: 5:33 - loss: 0.6663 - precision: 0.6152 - recall: 0.6178 - f1: 0.6055WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 840/4198 [=====>........................] - ETA: 5:32 - loss: 0.6651 - precision: 0.6161 - recall: 0.6191 - f1: 0.6065WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 850/4198 [=====>........................] - ETA: 5:31 - loss: 0.6641 - precision: 0.6169 - recall: 0.6203 - f1: 0.6076WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 860/4198 [=====>........................] - ETA: 5:30 - loss: 0.6631 - precision: 0.6173 - recall: 0.6217 - f1: 0.6085WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 870/4198 [=====>........................] - ETA: 5:29 - loss: 0.6624 - precision: 0.6176 - recall: 0.6223 - f1: 0.6090WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 880/4198 [=====>........................] - ETA: 5:29 - loss: 0.6616 - precision: 0.6183 - recall: 0.6227 - f1: 0.6096WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 890/4198 [=====>........................] - ETA: 5:28 - loss: 0.6603 - precision: 0.6196 - recall: 0.6237 - f1: 0.6108WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 900/4198 [=====>........................] - ETA: 5:27 - loss: 0.6585 - precision: 0.6209 - recall: 0.6259 - f1: 0.6126WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 910/4198 [=====>........................] - ETA: 5:26 - loss: 0.6581 - precision: 0.6213 - recall: 0.6262 - f1: 0.6130WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 920/4198 [=====>........................] - ETA: 5:25 - loss: 0.6572 - precision: 0.6222 - recall: 0.6267 - f1: 0.6136WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 930/4198 [=====>........................] - ETA: 5:24 - loss: 0.6568 - precision: 0.6227 - recall: 0.6261 - f1: 0.6136WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 940/4198 [=====>........................] - ETA: 5:23 - loss: 0.6562 - precision: 0.6231 - recall: 0.6269 - f1: 0.6143WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 950/4198 [=====>........................] - ETA: 5:22 - loss: 0.6555 - precision: 0.6234 - recall: 0.6272 - f1: 0.6147WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 960/4198 [=====>........................] - ETA: 5:21 - loss: 0.6547 - precision: 0.6244 - recall: 0.6274 - f1: 0.6152WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 970/4198 [=====>........................] - ETA: 5:20 - loss: 0.6543 - precision: 0.6247 - recall: 0.6276 - f1: 0.6155WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 980/4198 [======>.......................] - ETA: 5:19 - loss: 0.6535 - precision: 0.6259 - recall: 0.6288 - f1: 0.6167WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            " 990/4198 [======>.......................] - ETA: 5:18 - loss: 0.6524 - precision: 0.6269 - recall: 0.6299 - f1: 0.6178WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1000/4198 [======>.......................] - ETA: 5:17 - loss: 0.6515 - precision: 0.6273 - recall: 0.6300 - f1: 0.6181WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1010/4198 [======>.......................] - ETA: 5:16 - loss: 0.6503 - precision: 0.6281 - recall: 0.6307 - f1: 0.6190WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1020/4198 [======>.......................] - ETA: 5:15 - loss: 0.6497 - precision: 0.6285 - recall: 0.6307 - f1: 0.6192WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1030/4198 [======>.......................] - ETA: 5:14 - loss: 0.6485 - precision: 0.6295 - recall: 0.6311 - f1: 0.6200WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1040/4198 [======>.......................] - ETA: 5:13 - loss: 0.6478 - precision: 0.6301 - recall: 0.6316 - f1: 0.6206WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1050/4198 [======>.......................] - ETA: 5:12 - loss: 0.6476 - precision: 0.6302 - recall: 0.6309 - f1: 0.6203WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1060/4198 [======>.......................] - ETA: 5:11 - loss: 0.6466 - precision: 0.6312 - recall: 0.6326 - f1: 0.6217WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1070/4198 [======>.......................] - ETA: 5:10 - loss: 0.6458 - precision: 0.6318 - recall: 0.6346 - f1: 0.6229WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1080/4198 [======>.......................] - ETA: 5:09 - loss: 0.6447 - precision: 0.6331 - recall: 0.6354 - f1: 0.6240WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1090/4198 [======>.......................] - ETA: 5:08 - loss: 0.6440 - precision: 0.6336 - recall: 0.6356 - f1: 0.6243WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1100/4198 [======>.......................] - ETA: 5:07 - loss: 0.6436 - precision: 0.6338 - recall: 0.6358 - f1: 0.6245WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1110/4198 [======>.......................] - ETA: 5:06 - loss: 0.6429 - precision: 0.6339 - recall: 0.6353 - f1: 0.6242WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1120/4198 [=======>......................] - ETA: 5:05 - loss: 0.6423 - precision: 0.6347 - recall: 0.6356 - f1: 0.6248WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1130/4198 [=======>......................] - ETA: 5:04 - loss: 0.6416 - precision: 0.6351 - recall: 0.6356 - f1: 0.6250WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1140/4198 [=======>......................] - ETA: 5:03 - loss: 0.6413 - precision: 0.6354 - recall: 0.6365 - f1: 0.6256WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1150/4198 [=======>......................] - ETA: 5:02 - loss: 0.6408 - precision: 0.6360 - recall: 0.6372 - f1: 0.6263WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1160/4198 [=======>......................] - ETA: 5:01 - loss: 0.6404 - precision: 0.6362 - recall: 0.6375 - f1: 0.6266WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1170/4198 [=======>......................] - ETA: 5:00 - loss: 0.6397 - precision: 0.6370 - recall: 0.6385 - f1: 0.6275WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1180/4198 [=======>......................] - ETA: 4:59 - loss: 0.6389 - precision: 0.6372 - recall: 0.6396 - f1: 0.6282WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1190/4198 [=======>......................] - ETA: 4:58 - loss: 0.6382 - precision: 0.6379 - recall: 0.6400 - f1: 0.6287WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1200/4198 [=======>......................] - ETA: 4:57 - loss: 0.6377 - precision: 0.6385 - recall: 0.6408 - f1: 0.6294WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1210/4198 [=======>......................] - ETA: 4:55 - loss: 0.6371 - precision: 0.6387 - recall: 0.6405 - f1: 0.6294WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1220/4198 [=======>......................] - ETA: 4:55 - loss: 0.6370 - precision: 0.6390 - recall: 0.6405 - f1: 0.6296WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1230/4198 [=======>......................] - ETA: 4:54 - loss: 0.6366 - precision: 0.6394 - recall: 0.6410 - f1: 0.6300WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1240/4198 [=======>......................] - ETA: 4:53 - loss: 0.6364 - precision: 0.6397 - recall: 0.6410 - f1: 0.6302WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1250/4198 [=======>......................] - ETA: 4:52 - loss: 0.6361 - precision: 0.6399 - recall: 0.6413 - f1: 0.6305WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1260/4198 [========>.....................] - ETA: 4:51 - loss: 0.6360 - precision: 0.6400 - recall: 0.6414 - f1: 0.6306WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1270/4198 [========>.....................] - ETA: 4:50 - loss: 0.6352 - precision: 0.6413 - recall: 0.6415 - f1: 0.6313WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1280/4198 [========>.....................] - ETA: 4:49 - loss: 0.6348 - precision: 0.6414 - recall: 0.6420 - f1: 0.6317WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1290/4198 [========>.....................] - ETA: 4:48 - loss: 0.6344 - precision: 0.6418 - recall: 0.6423 - f1: 0.6320WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1300/4198 [========>.....................] - ETA: 4:47 - loss: 0.6342 - precision: 0.6420 - recall: 0.6422 - f1: 0.6321WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1310/4198 [========>.....................] - ETA: 4:46 - loss: 0.6334 - precision: 0.6428 - recall: 0.6430 - f1: 0.6329WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1320/4198 [========>.....................] - ETA: 4:45 - loss: 0.6330 - precision: 0.6428 - recall: 0.6437 - f1: 0.6333WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1330/4198 [========>.....................] - ETA: 4:44 - loss: 0.6323 - precision: 0.6435 - recall: 0.6444 - f1: 0.6340WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1340/4198 [========>.....................] - ETA: 4:43 - loss: 0.6318 - precision: 0.6437 - recall: 0.6446 - f1: 0.6342WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1350/4198 [========>.....................] - ETA: 4:42 - loss: 0.6313 - precision: 0.6440 - recall: 0.6448 - f1: 0.6345WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1360/4198 [========>.....................] - ETA: 4:41 - loss: 0.6306 - precision: 0.6449 - recall: 0.6451 - f1: 0.6351WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1370/4198 [========>.....................] - ETA: 4:40 - loss: 0.6298 - precision: 0.6454 - recall: 0.6457 - f1: 0.6356WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1380/4198 [========>.....................] - ETA: 4:39 - loss: 0.6292 - precision: 0.6459 - recall: 0.6457 - f1: 0.6359WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1390/4198 [========>.....................] - ETA: 4:38 - loss: 0.6286 - precision: 0.6467 - recall: 0.6459 - f1: 0.6363WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1400/4198 [=========>....................] - ETA: 4:37 - loss: 0.6279 - precision: 0.6470 - recall: 0.6466 - f1: 0.6368WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1410/4198 [=========>....................] - ETA: 4:36 - loss: 0.6273 - precision: 0.6475 - recall: 0.6468 - f1: 0.6372WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1420/4198 [=========>....................] - ETA: 4:35 - loss: 0.6268 - precision: 0.6481 - recall: 0.6470 - f1: 0.6375WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1430/4198 [=========>....................] - ETA: 4:34 - loss: 0.6263 - precision: 0.6484 - recall: 0.6479 - f1: 0.6382WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1440/4198 [=========>....................] - ETA: 4:33 - loss: 0.6259 - precision: 0.6489 - recall: 0.6486 - f1: 0.6387WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1450/4198 [=========>....................] - ETA: 4:32 - loss: 0.6254 - precision: 0.6495 - recall: 0.6487 - f1: 0.6391WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1460/4198 [=========>....................] - ETA: 4:31 - loss: 0.6248 - precision: 0.6500 - recall: 0.6498 - f1: 0.6399WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1470/4198 [=========>....................] - ETA: 4:30 - loss: 0.6245 - precision: 0.6504 - recall: 0.6499 - f1: 0.6401WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1480/4198 [=========>....................] - ETA: 4:29 - loss: 0.6241 - precision: 0.6505 - recall: 0.6501 - f1: 0.6403WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1490/4198 [=========>....................] - ETA: 4:28 - loss: 0.6238 - precision: 0.6504 - recall: 0.6504 - f1: 0.6405WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1500/4198 [=========>....................] - ETA: 4:27 - loss: 0.6239 - precision: 0.6506 - recall: 0.6507 - f1: 0.6407WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1510/4198 [=========>....................] - ETA: 4:26 - loss: 0.6236 - precision: 0.6507 - recall: 0.6511 - f1: 0.6410WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1520/4198 [=========>....................] - ETA: 4:26 - loss: 0.6232 - precision: 0.6513 - recall: 0.6511 - f1: 0.6413WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1530/4198 [=========>....................] - ETA: 4:25 - loss: 0.6229 - precision: 0.6515 - recall: 0.6515 - f1: 0.6417WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1540/4198 [==========>...................] - ETA: 4:24 - loss: 0.6226 - precision: 0.6520 - recall: 0.6519 - f1: 0.6421WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1550/4198 [==========>...................] - ETA: 4:23 - loss: 0.6218 - precision: 0.6526 - recall: 0.6526 - f1: 0.6428WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1560/4198 [==========>...................] - ETA: 4:22 - loss: 0.6212 - precision: 0.6533 - recall: 0.6532 - f1: 0.6435WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1570/4198 [==========>...................] - ETA: 4:20 - loss: 0.6209 - precision: 0.6536 - recall: 0.6533 - f1: 0.6437WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1580/4198 [==========>...................] - ETA: 4:20 - loss: 0.6204 - precision: 0.6544 - recall: 0.6540 - f1: 0.6444WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1590/4198 [==========>...................] - ETA: 4:19 - loss: 0.6199 - precision: 0.6547 - recall: 0.6546 - f1: 0.6449WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1600/4198 [==========>...................] - ETA: 4:18 - loss: 0.6194 - precision: 0.6551 - recall: 0.6549 - f1: 0.6453WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1610/4198 [==========>...................] - ETA: 4:17 - loss: 0.6191 - precision: 0.6555 - recall: 0.6552 - f1: 0.6456WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1620/4198 [==========>...................] - ETA: 4:16 - loss: 0.6188 - precision: 0.6559 - recall: 0.6555 - f1: 0.6460WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1630/4198 [==========>...................] - ETA: 4:15 - loss: 0.6182 - precision: 0.6563 - recall: 0.6554 - f1: 0.6461WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1640/4198 [==========>...................] - ETA: 4:14 - loss: 0.6177 - precision: 0.6565 - recall: 0.6558 - f1: 0.6464WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1650/4198 [==========>...................] - ETA: 4:13 - loss: 0.6173 - precision: 0.6569 - recall: 0.6555 - f1: 0.6465WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1660/4198 [==========>...................] - ETA: 4:12 - loss: 0.6168 - precision: 0.6573 - recall: 0.6558 - f1: 0.6469WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1670/4198 [==========>...................] - ETA: 4:11 - loss: 0.6163 - precision: 0.6576 - recall: 0.6565 - f1: 0.6473WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1680/4198 [===========>..................] - ETA: 4:10 - loss: 0.6160 - precision: 0.6579 - recall: 0.6568 - f1: 0.6477WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1690/4198 [===========>..................] - ETA: 4:09 - loss: 0.6158 - precision: 0.6584 - recall: 0.6574 - f1: 0.6482WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1700/4198 [===========>..................] - ETA: 4:08 - loss: 0.6155 - precision: 0.6584 - recall: 0.6577 - f1: 0.6484WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1710/4198 [===========>..................] - ETA: 4:07 - loss: 0.6152 - precision: 0.6587 - recall: 0.6574 - f1: 0.6484WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1720/4198 [===========>..................] - ETA: 4:06 - loss: 0.6149 - precision: 0.6585 - recall: 0.6575 - f1: 0.6484WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1730/4198 [===========>..................] - ETA: 4:05 - loss: 0.6144 - precision: 0.6591 - recall: 0.6577 - f1: 0.6488WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1740/4198 [===========>..................] - ETA: 4:04 - loss: 0.6142 - precision: 0.6598 - recall: 0.6573 - f1: 0.6489WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1750/4198 [===========>..................] - ETA: 4:03 - loss: 0.6138 - precision: 0.6600 - recall: 0.6579 - f1: 0.6493WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1760/4198 [===========>..................] - ETA: 4:02 - loss: 0.6134 - precision: 0.6603 - recall: 0.6583 - f1: 0.6497WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1770/4198 [===========>..................] - ETA: 4:01 - loss: 0.6130 - precision: 0.6604 - recall: 0.6585 - f1: 0.6499WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1780/4198 [===========>..................] - ETA: 4:00 - loss: 0.6129 - precision: 0.6609 - recall: 0.6584 - f1: 0.6500WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1790/4198 [===========>..................] - ETA: 3:59 - loss: 0.6128 - precision: 0.6612 - recall: 0.6585 - f1: 0.6503WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1800/4198 [===========>..................] - ETA: 3:58 - loss: 0.6124 - precision: 0.6615 - recall: 0.6590 - f1: 0.6507WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1810/4198 [===========>..................] - ETA: 3:57 - loss: 0.6122 - precision: 0.6617 - recall: 0.6592 - f1: 0.6509WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1820/4198 [============>.................] - ETA: 3:56 - loss: 0.6116 - precision: 0.6625 - recall: 0.6595 - f1: 0.6514WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1830/4198 [============>.................] - ETA: 3:55 - loss: 0.6109 - precision: 0.6631 - recall: 0.6598 - f1: 0.6519WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1840/4198 [============>.................] - ETA: 3:54 - loss: 0.6104 - precision: 0.6635 - recall: 0.6604 - f1: 0.6524WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1850/4198 [============>.................] - ETA: 3:53 - loss: 0.6102 - precision: 0.6638 - recall: 0.6605 - f1: 0.6526WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1860/4198 [============>.................] - ETA: 3:52 - loss: 0.6096 - precision: 0.6638 - recall: 0.6608 - f1: 0.6528WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1870/4198 [============>.................] - ETA: 3:51 - loss: 0.6094 - precision: 0.6642 - recall: 0.6610 - f1: 0.6531WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1880/4198 [============>.................] - ETA: 3:50 - loss: 0.6092 - precision: 0.6643 - recall: 0.6615 - f1: 0.6534WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1890/4198 [============>.................] - ETA: 3:49 - loss: 0.6089 - precision: 0.6642 - recall: 0.6619 - f1: 0.6536WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1900/4198 [============>.................] - ETA: 3:48 - loss: 0.6086 - precision: 0.6648 - recall: 0.6617 - f1: 0.6537WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1910/4198 [============>.................] - ETA: 3:47 - loss: 0.6083 - precision: 0.6651 - recall: 0.6621 - f1: 0.6541WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1920/4198 [============>.................] - ETA: 3:46 - loss: 0.6080 - precision: 0.6653 - recall: 0.6627 - f1: 0.6545WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1930/4198 [============>.................] - ETA: 3:45 - loss: 0.6076 - precision: 0.6655 - recall: 0.6631 - f1: 0.6547WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1940/4198 [============>.................] - ETA: 3:44 - loss: 0.6074 - precision: 0.6658 - recall: 0.6632 - f1: 0.6550WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1950/4198 [============>.................] - ETA: 3:43 - loss: 0.6068 - precision: 0.6664 - recall: 0.6638 - f1: 0.6556WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1960/4198 [=============>................] - ETA: 3:42 - loss: 0.6068 - precision: 0.6665 - recall: 0.6641 - f1: 0.6558WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1970/4198 [=============>................] - ETA: 3:41 - loss: 0.6065 - precision: 0.6666 - recall: 0.6644 - f1: 0.6560WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1980/4198 [=============>................] - ETA: 3:40 - loss: 0.6064 - precision: 0.6669 - recall: 0.6644 - f1: 0.6562WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "1990/4198 [=============>................] - ETA: 3:39 - loss: 0.6062 - precision: 0.6673 - recall: 0.6646 - f1: 0.6565WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2000/4198 [=============>................] - ETA: 3:38 - loss: 0.6061 - precision: 0.6669 - recall: 0.6652 - f1: 0.6565WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2010/4198 [=============>................] - ETA: 3:37 - loss: 0.6058 - precision: 0.6674 - recall: 0.6650 - f1: 0.6566WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2020/4198 [=============>................] - ETA: 3:36 - loss: 0.6055 - precision: 0.6676 - recall: 0.6654 - f1: 0.6570WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2030/4198 [=============>................] - ETA: 3:35 - loss: 0.6049 - precision: 0.6681 - recall: 0.6660 - f1: 0.6576WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2040/4198 [=============>................] - ETA: 3:34 - loss: 0.6047 - precision: 0.6683 - recall: 0.6654 - f1: 0.6573WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2050/4198 [=============>................] - ETA: 3:33 - loss: 0.6045 - precision: 0.6685 - recall: 0.6656 - f1: 0.6576WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2060/4198 [=============>................] - ETA: 3:32 - loss: 0.6044 - precision: 0.6686 - recall: 0.6659 - f1: 0.6577WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2070/4198 [=============>................] - ETA: 3:31 - loss: 0.6043 - precision: 0.6687 - recall: 0.6660 - f1: 0.6578WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2080/4198 [=============>................] - ETA: 3:30 - loss: 0.6041 - precision: 0.6687 - recall: 0.6659 - f1: 0.6578WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2090/4198 [=============>................] - ETA: 3:29 - loss: 0.6037 - precision: 0.6693 - recall: 0.6660 - f1: 0.6581WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2100/4198 [==============>...............] - ETA: 3:29 - loss: 0.6033 - precision: 0.6697 - recall: 0.6661 - f1: 0.6584WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2110/4198 [==============>...............] - ETA: 3:28 - loss: 0.6030 - precision: 0.6702 - recall: 0.6665 - f1: 0.6589WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2120/4198 [==============>...............] - ETA: 3:27 - loss: 0.6027 - precision: 0.6704 - recall: 0.6670 - f1: 0.6592WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2130/4198 [==============>...............] - ETA: 3:26 - loss: 0.6025 - precision: 0.6705 - recall: 0.6672 - f1: 0.6594WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2140/4198 [==============>...............] - ETA: 3:25 - loss: 0.6023 - precision: 0.6707 - recall: 0.6674 - f1: 0.6596WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2150/4198 [==============>...............] - ETA: 3:24 - loss: 0.6019 - precision: 0.6712 - recall: 0.6673 - f1: 0.6598WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2160/4198 [==============>...............] - ETA: 3:23 - loss: 0.6017 - precision: 0.6714 - recall: 0.6679 - f1: 0.6602WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2170/4198 [==============>...............] - ETA: 3:22 - loss: 0.6013 - precision: 0.6716 - recall: 0.6684 - f1: 0.6605WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2180/4198 [==============>...............] - ETA: 3:21 - loss: 0.6010 - precision: 0.6716 - recall: 0.6686 - f1: 0.6606WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2190/4198 [==============>...............] - ETA: 3:20 - loss: 0.6008 - precision: 0.6719 - recall: 0.6687 - f1: 0.6609WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2200/4198 [==============>...............] - ETA: 3:19 - loss: 0.6005 - precision: 0.6722 - recall: 0.6691 - f1: 0.6613WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2210/4198 [==============>...............] - ETA: 3:18 - loss: 0.6002 - precision: 0.6723 - recall: 0.6694 - f1: 0.6615WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2220/4198 [==============>...............] - ETA: 3:17 - loss: 0.5998 - precision: 0.6725 - recall: 0.6697 - f1: 0.6617WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2230/4198 [==============>...............] - ETA: 3:16 - loss: 0.5996 - precision: 0.6727 - recall: 0.6695 - f1: 0.6617WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2240/4198 [===============>..............] - ETA: 3:15 - loss: 0.5994 - precision: 0.6730 - recall: 0.6695 - f1: 0.6618WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2250/4198 [===============>..............] - ETA: 3:14 - loss: 0.5991 - precision: 0.6733 - recall: 0.6698 - f1: 0.6621WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2260/4198 [===============>..............] - ETA: 3:13 - loss: 0.5987 - precision: 0.6735 - recall: 0.6703 - f1: 0.6625WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2270/4198 [===============>..............] - ETA: 3:12 - loss: 0.5984 - precision: 0.6739 - recall: 0.6705 - f1: 0.6628WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2280/4198 [===============>..............] - ETA: 3:11 - loss: 0.5982 - precision: 0.6740 - recall: 0.6708 - f1: 0.6630WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2290/4198 [===============>..............] - ETA: 3:10 - loss: 0.5980 - precision: 0.6741 - recall: 0.6708 - f1: 0.6631WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2300/4198 [===============>..............] - ETA: 3:09 - loss: 0.5977 - precision: 0.6745 - recall: 0.6708 - f1: 0.6632WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2310/4198 [===============>..............] - ETA: 3:08 - loss: 0.5974 - precision: 0.6747 - recall: 0.6712 - f1: 0.6636WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2320/4198 [===============>..............] - ETA: 3:07 - loss: 0.5972 - precision: 0.6747 - recall: 0.6712 - f1: 0.6636WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2330/4198 [===============>..............] - ETA: 3:06 - loss: 0.5969 - precision: 0.6749 - recall: 0.6714 - f1: 0.6638WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2340/4198 [===============>..............] - ETA: 3:05 - loss: 0.5966 - precision: 0.6751 - recall: 0.6715 - f1: 0.6640WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2350/4198 [===============>..............] - ETA: 3:04 - loss: 0.5964 - precision: 0.6753 - recall: 0.6719 - f1: 0.6643WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2360/4198 [===============>..............] - ETA: 3:03 - loss: 0.5962 - precision: 0.6755 - recall: 0.6721 - f1: 0.6645WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2370/4198 [===============>..............] - ETA: 3:02 - loss: 0.5959 - precision: 0.6759 - recall: 0.6723 - f1: 0.6648WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2380/4198 [================>.............] - ETA: 3:01 - loss: 0.5957 - precision: 0.6760 - recall: 0.6723 - f1: 0.6649WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2390/4198 [================>.............] - ETA: 3:00 - loss: 0.5954 - precision: 0.6762 - recall: 0.6728 - f1: 0.6652WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2400/4198 [================>.............] - ETA: 2:59 - loss: 0.5952 - precision: 0.6764 - recall: 0.6728 - f1: 0.6654WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2410/4198 [================>.............] - ETA: 2:58 - loss: 0.5949 - precision: 0.6767 - recall: 0.6726 - f1: 0.6654WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2420/4198 [================>.............] - ETA: 2:57 - loss: 0.5946 - precision: 0.6770 - recall: 0.6731 - f1: 0.6658WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2430/4198 [================>.............] - ETA: 2:56 - loss: 0.5942 - precision: 0.6773 - recall: 0.6734 - f1: 0.6661WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2440/4198 [================>.............] - ETA: 2:55 - loss: 0.5940 - precision: 0.6774 - recall: 0.6739 - f1: 0.6664WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2450/4198 [================>.............] - ETA: 2:54 - loss: 0.5936 - precision: 0.6778 - recall: 0.6740 - f1: 0.6667WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2460/4198 [================>.............] - ETA: 2:53 - loss: 0.5935 - precision: 0.6779 - recall: 0.6743 - f1: 0.6668WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2470/4198 [================>.............] - ETA: 2:52 - loss: 0.5932 - precision: 0.6781 - recall: 0.6745 - f1: 0.6671WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2480/4198 [================>.............] - ETA: 2:51 - loss: 0.5932 - precision: 0.6781 - recall: 0.6747 - f1: 0.6672WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2490/4198 [================>.............] - ETA: 2:50 - loss: 0.5931 - precision: 0.6784 - recall: 0.6746 - f1: 0.6673WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2500/4198 [================>.............] - ETA: 2:49 - loss: 0.5930 - precision: 0.6784 - recall: 0.6750 - f1: 0.6674WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2510/4198 [================>.............] - ETA: 2:48 - loss: 0.5929 - precision: 0.6786 - recall: 0.6752 - f1: 0.6676WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2520/4198 [=================>............] - ETA: 2:47 - loss: 0.5926 - precision: 0.6788 - recall: 0.6751 - f1: 0.6677WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2530/4198 [=================>............] - ETA: 2:46 - loss: 0.5922 - precision: 0.6792 - recall: 0.6751 - f1: 0.6679WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2540/4198 [=================>............] - ETA: 2:45 - loss: 0.5921 - precision: 0.6793 - recall: 0.6754 - f1: 0.6681WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2550/4198 [=================>............] - ETA: 2:44 - loss: 0.5919 - precision: 0.6794 - recall: 0.6758 - f1: 0.6683WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2560/4198 [=================>............] - ETA: 2:44 - loss: 0.5917 - precision: 0.6797 - recall: 0.6758 - f1: 0.6685WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2570/4198 [=================>............] - ETA: 2:43 - loss: 0.5916 - precision: 0.6797 - recall: 0.6759 - f1: 0.6686WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2580/4198 [=================>............] - ETA: 2:42 - loss: 0.5915 - precision: 0.6800 - recall: 0.6755 - f1: 0.6684WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2590/4198 [=================>............] - ETA: 2:41 - loss: 0.5912 - precision: 0.6802 - recall: 0.6757 - f1: 0.6687WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2600/4198 [=================>............] - ETA: 2:40 - loss: 0.5910 - precision: 0.6803 - recall: 0.6759 - f1: 0.6688WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2610/4198 [=================>............] - ETA: 2:39 - loss: 0.5909 - precision: 0.6805 - recall: 0.6760 - f1: 0.6690WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2620/4198 [=================>............] - ETA: 2:38 - loss: 0.5907 - precision: 0.6808 - recall: 0.6762 - f1: 0.6692WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2630/4198 [=================>............] - ETA: 2:37 - loss: 0.5903 - precision: 0.6813 - recall: 0.6767 - f1: 0.6697WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2640/4198 [=================>............] - ETA: 2:36 - loss: 0.5899 - precision: 0.6813 - recall: 0.6773 - f1: 0.6700WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2650/4198 [=================>............] - ETA: 2:35 - loss: 0.5897 - precision: 0.6815 - recall: 0.6773 - f1: 0.6702WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2660/4198 [==================>...........] - ETA: 2:34 - loss: 0.5896 - precision: 0.6819 - recall: 0.6772 - f1: 0.6703WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2670/4198 [==================>...........] - ETA: 2:33 - loss: 0.5893 - precision: 0.6823 - recall: 0.6775 - f1: 0.6707WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2680/4198 [==================>...........] - ETA: 2:32 - loss: 0.5893 - precision: 0.6823 - recall: 0.6780 - f1: 0.6709WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2690/4198 [==================>...........] - ETA: 2:31 - loss: 0.5891 - precision: 0.6824 - recall: 0.6783 - f1: 0.6711WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2700/4198 [==================>...........] - ETA: 2:30 - loss: 0.5889 - precision: 0.6826 - recall: 0.6786 - f1: 0.6714WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2710/4198 [==================>...........] - ETA: 2:29 - loss: 0.5886 - precision: 0.6829 - recall: 0.6789 - f1: 0.6717WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2720/4198 [==================>...........] - ETA: 2:28 - loss: 0.5885 - precision: 0.6830 - recall: 0.6787 - f1: 0.6717WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2730/4198 [==================>...........] - ETA: 2:27 - loss: 0.5883 - precision: 0.6832 - recall: 0.6791 - f1: 0.6720WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2740/4198 [==================>...........] - ETA: 2:26 - loss: 0.5881 - precision: 0.6834 - recall: 0.6792 - f1: 0.6721WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2750/4198 [==================>...........] - ETA: 2:25 - loss: 0.5881 - precision: 0.6834 - recall: 0.6794 - f1: 0.6722WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2760/4198 [==================>...........] - ETA: 2:24 - loss: 0.5879 - precision: 0.6835 - recall: 0.6794 - f1: 0.6723WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2770/4198 [==================>...........] - ETA: 2:23 - loss: 0.5878 - precision: 0.6837 - recall: 0.6795 - f1: 0.6724WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2780/4198 [==================>...........] - ETA: 2:22 - loss: 0.5876 - precision: 0.6839 - recall: 0.6798 - f1: 0.6727WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2790/4198 [==================>...........] - ETA: 2:21 - loss: 0.5872 - precision: 0.6842 - recall: 0.6802 - f1: 0.6730WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2800/4198 [===================>..........] - ETA: 2:20 - loss: 0.5871 - precision: 0.6841 - recall: 0.6803 - f1: 0.6730WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2810/4198 [===================>..........] - ETA: 2:19 - loss: 0.5869 - precision: 0.6843 - recall: 0.6802 - f1: 0.6731WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2820/4198 [===================>..........] - ETA: 2:18 - loss: 0.5868 - precision: 0.6846 - recall: 0.6803 - f1: 0.6732WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2830/4198 [===================>..........] - ETA: 2:17 - loss: 0.5867 - precision: 0.6846 - recall: 0.6807 - f1: 0.6735WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2840/4198 [===================>..........] - ETA: 2:16 - loss: 0.5864 - precision: 0.6848 - recall: 0.6811 - f1: 0.6738WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2850/4198 [===================>..........] - ETA: 2:15 - loss: 0.5863 - precision: 0.6849 - recall: 0.6811 - f1: 0.6738WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2860/4198 [===================>..........] - ETA: 2:14 - loss: 0.5862 - precision: 0.6850 - recall: 0.6811 - f1: 0.6739WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2870/4198 [===================>..........] - ETA: 2:13 - loss: 0.5860 - precision: 0.6852 - recall: 0.6814 - f1: 0.6742WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2880/4198 [===================>..........] - ETA: 2:12 - loss: 0.5857 - precision: 0.6855 - recall: 0.6814 - f1: 0.6743WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2890/4198 [===================>..........] - ETA: 2:11 - loss: 0.5855 - precision: 0.6858 - recall: 0.6816 - f1: 0.6745WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2900/4198 [===================>..........] - ETA: 2:10 - loss: 0.5854 - precision: 0.6859 - recall: 0.6818 - f1: 0.6747WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2910/4198 [===================>..........] - ETA: 2:09 - loss: 0.5854 - precision: 0.6858 - recall: 0.6817 - f1: 0.6746WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2920/4198 [===================>..........] - ETA: 2:08 - loss: 0.5852 - precision: 0.6861 - recall: 0.6816 - f1: 0.6747WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2930/4198 [===================>..........] - ETA: 2:07 - loss: 0.5850 - precision: 0.6861 - recall: 0.6819 - f1: 0.6748WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2940/4198 [====================>.........] - ETA: 2:06 - loss: 0.5849 - precision: 0.6863 - recall: 0.6818 - f1: 0.6749WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2950/4198 [====================>.........] - ETA: 2:05 - loss: 0.5845 - precision: 0.6865 - recall: 0.6823 - f1: 0.6753WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2960/4198 [====================>.........] - ETA: 2:04 - loss: 0.5843 - precision: 0.6867 - recall: 0.6827 - f1: 0.6756WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2970/4198 [====================>.........] - ETA: 2:03 - loss: 0.5840 - precision: 0.6870 - recall: 0.6829 - f1: 0.6758WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2980/4198 [====================>.........] - ETA: 2:02 - loss: 0.5838 - precision: 0.6872 - recall: 0.6832 - f1: 0.6761WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "2990/4198 [====================>.........] - ETA: 2:01 - loss: 0.5836 - precision: 0.6875 - recall: 0.6833 - f1: 0.6763WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3000/4198 [====================>.........] - ETA: 2:00 - loss: 0.5834 - precision: 0.6876 - recall: 0.6837 - f1: 0.6766WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3010/4198 [====================>.........] - ETA: 1:59 - loss: 0.5833 - precision: 0.6876 - recall: 0.6839 - f1: 0.6767WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3020/4198 [====================>.........] - ETA: 1:58 - loss: 0.5832 - precision: 0.6878 - recall: 0.6840 - f1: 0.6768WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3030/4198 [====================>.........] - ETA: 1:57 - loss: 0.5828 - precision: 0.6881 - recall: 0.6844 - f1: 0.6772WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3040/4198 [====================>.........] - ETA: 1:56 - loss: 0.5826 - precision: 0.6882 - recall: 0.6846 - f1: 0.6774WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3050/4198 [====================>.........] - ETA: 1:55 - loss: 0.5826 - precision: 0.6881 - recall: 0.6849 - f1: 0.6775WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3060/4198 [====================>.........] - ETA: 1:54 - loss: 0.5826 - precision: 0.6881 - recall: 0.6851 - f1: 0.6776WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3070/4198 [====================>.........] - ETA: 1:53 - loss: 0.5824 - precision: 0.6882 - recall: 0.6853 - f1: 0.6777WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3080/4198 [=====================>........] - ETA: 1:52 - loss: 0.5823 - precision: 0.6884 - recall: 0.6851 - f1: 0.6777WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3090/4198 [=====================>........] - ETA: 1:51 - loss: 0.5822 - precision: 0.6885 - recall: 0.6853 - f1: 0.6779WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3100/4198 [=====================>........] - ETA: 1:50 - loss: 0.5821 - precision: 0.6885 - recall: 0.6856 - f1: 0.6780WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3110/4198 [=====================>........] - ETA: 1:49 - loss: 0.5819 - precision: 0.6886 - recall: 0.6857 - f1: 0.6781WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3120/4198 [=====================>........] - ETA: 1:48 - loss: 0.5817 - precision: 0.6887 - recall: 0.6859 - f1: 0.6783WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3130/4198 [=====================>........] - ETA: 1:47 - loss: 0.5815 - precision: 0.6888 - recall: 0.6860 - f1: 0.6784WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3140/4198 [=====================>........] - ETA: 1:46 - loss: 0.5812 - precision: 0.6889 - recall: 0.6862 - f1: 0.6786WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3150/4198 [=====================>........] - ETA: 1:45 - loss: 0.5809 - precision: 0.6891 - recall: 0.6865 - f1: 0.6788WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3160/4198 [=====================>........] - ETA: 1:44 - loss: 0.5808 - precision: 0.6892 - recall: 0.6863 - f1: 0.6788WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3170/4198 [=====================>........] - ETA: 1:43 - loss: 0.5805 - precision: 0.6896 - recall: 0.6866 - f1: 0.6791WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3180/4198 [=====================>........] - ETA: 1:42 - loss: 0.5804 - precision: 0.6896 - recall: 0.6869 - f1: 0.6793WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3190/4198 [=====================>........] - ETA: 1:41 - loss: 0.5803 - precision: 0.6896 - recall: 0.6871 - f1: 0.6794WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3200/4198 [=====================>........] - ETA: 1:40 - loss: 0.5799 - precision: 0.6898 - recall: 0.6874 - f1: 0.6797WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3210/4198 [=====================>........] - ETA: 1:39 - loss: 0.5798 - precision: 0.6901 - recall: 0.6875 - f1: 0.6799WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3220/4198 [======================>.......] - ETA: 1:38 - loss: 0.5796 - precision: 0.6901 - recall: 0.6878 - f1: 0.6800WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3230/4198 [======================>.......] - ETA: 1:37 - loss: 0.5795 - precision: 0.6902 - recall: 0.6877 - f1: 0.6800WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3240/4198 [======================>.......] - ETA: 1:36 - loss: 0.5794 - precision: 0.6903 - recall: 0.6876 - f1: 0.6800WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3250/4198 [======================>.......] - ETA: 1:35 - loss: 0.5793 - precision: 0.6905 - recall: 0.6878 - f1: 0.6802WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3260/4198 [======================>.......] - ETA: 1:34 - loss: 0.5791 - precision: 0.6905 - recall: 0.6882 - f1: 0.6804WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3270/4198 [======================>.......] - ETA: 1:33 - loss: 0.5789 - precision: 0.6906 - recall: 0.6883 - f1: 0.6805WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3280/4198 [======================>.......] - ETA: 1:32 - loss: 0.5788 - precision: 0.6907 - recall: 0.6883 - f1: 0.6806WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3290/4198 [======================>.......] - ETA: 1:31 - loss: 0.5786 - precision: 0.6907 - recall: 0.6886 - f1: 0.6807WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3300/4198 [======================>.......] - ETA: 1:30 - loss: 0.5787 - precision: 0.6907 - recall: 0.6885 - f1: 0.6807WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3310/4198 [======================>.......] - ETA: 1:29 - loss: 0.5787 - precision: 0.6907 - recall: 0.6883 - f1: 0.6806WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3320/4198 [======================>.......] - ETA: 1:28 - loss: 0.5785 - precision: 0.6909 - recall: 0.6886 - f1: 0.6808WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3330/4198 [======================>.......] - ETA: 1:27 - loss: 0.5782 - precision: 0.6911 - recall: 0.6888 - f1: 0.6810WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3340/4198 [======================>.......] - ETA: 1:26 - loss: 0.5781 - precision: 0.6911 - recall: 0.6888 - f1: 0.6810WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3350/4198 [======================>.......] - ETA: 1:25 - loss: 0.5779 - precision: 0.6912 - recall: 0.6892 - f1: 0.6812WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3360/4198 [=======================>......] - ETA: 1:24 - loss: 0.5778 - precision: 0.6914 - recall: 0.6893 - f1: 0.6814WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3370/4198 [=======================>......] - ETA: 1:23 - loss: 0.5779 - precision: 0.6913 - recall: 0.6891 - f1: 0.6813WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3380/4198 [=======================>......] - ETA: 1:22 - loss: 0.5778 - precision: 0.6913 - recall: 0.6894 - f1: 0.6814WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3390/4198 [=======================>......] - ETA: 1:21 - loss: 0.5776 - precision: 0.6914 - recall: 0.6896 - f1: 0.6816WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3400/4198 [=======================>......] - ETA: 1:20 - loss: 0.5776 - precision: 0.6916 - recall: 0.6895 - f1: 0.6816WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3410/4198 [=======================>......] - ETA: 1:19 - loss: 0.5775 - precision: 0.6916 - recall: 0.6895 - f1: 0.6816WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3420/4198 [=======================>......] - ETA: 1:18 - loss: 0.5774 - precision: 0.6918 - recall: 0.6896 - f1: 0.6818WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3430/4198 [=======================>......] - ETA: 1:17 - loss: 0.5773 - precision: 0.6919 - recall: 0.6900 - f1: 0.6820WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3440/4198 [=======================>......] - ETA: 1:16 - loss: 0.5772 - precision: 0.6919 - recall: 0.6902 - f1: 0.6821WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3450/4198 [=======================>......] - ETA: 1:15 - loss: 0.5771 - precision: 0.6922 - recall: 0.6901 - f1: 0.6822WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3460/4198 [=======================>......] - ETA: 1:14 - loss: 0.5769 - precision: 0.6923 - recall: 0.6903 - f1: 0.6823WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3470/4198 [=======================>......] - ETA: 1:13 - loss: 0.5768 - precision: 0.6923 - recall: 0.6904 - f1: 0.6824WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3480/4198 [=======================>......] - ETA: 1:12 - loss: 0.5767 - precision: 0.6923 - recall: 0.6904 - f1: 0.6824WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3490/4198 [=======================>......] - ETA: 1:11 - loss: 0.5766 - precision: 0.6923 - recall: 0.6903 - f1: 0.6824WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3500/4198 [========================>.....] - ETA: 1:10 - loss: 0.5764 - precision: 0.6924 - recall: 0.6905 - f1: 0.6826WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3510/4198 [========================>.....] - ETA: 1:09 - loss: 0.5763 - precision: 0.6924 - recall: 0.6906 - f1: 0.6826WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3520/4198 [========================>.....] - ETA: 1:08 - loss: 0.5763 - precision: 0.6924 - recall: 0.6904 - f1: 0.6825WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3530/4198 [========================>.....] - ETA: 1:07 - loss: 0.5761 - precision: 0.6926 - recall: 0.6906 - f1: 0.6827WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3540/4198 [========================>.....] - ETA: 1:06 - loss: 0.5762 - precision: 0.6926 - recall: 0.6907 - f1: 0.6828WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3550/4198 [========================>.....] - ETA: 1:05 - loss: 0.5761 - precision: 0.6927 - recall: 0.6908 - f1: 0.6829WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3560/4198 [========================>.....] - ETA: 1:04 - loss: 0.5760 - precision: 0.6927 - recall: 0.6909 - f1: 0.6830WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3570/4198 [========================>.....] - ETA: 1:03 - loss: 0.5760 - precision: 0.6929 - recall: 0.6907 - f1: 0.6829WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3580/4198 [========================>.....] - ETA: 1:02 - loss: 0.5758 - precision: 0.6930 - recall: 0.6909 - f1: 0.6831WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3590/4198 [========================>.....] - ETA: 1:01 - loss: 0.5757 - precision: 0.6931 - recall: 0.6912 - f1: 0.6833WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3600/4198 [========================>.....] - ETA: 1:00 - loss: 0.5756 - precision: 0.6933 - recall: 0.6912 - f1: 0.6834WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3610/4198 [========================>.....] - ETA: 59s - loss: 0.5756 - precision: 0.6932 - recall: 0.6909 - f1: 0.6832WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3620/4198 [========================>.....] - ETA: 58s - loss: 0.5754 - precision: 0.6934 - recall: 0.6911 - f1: 0.6834WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3630/4198 [========================>.....] - ETA: 57s - loss: 0.5753 - precision: 0.6935 - recall: 0.6914 - f1: 0.6836WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3640/4198 [=========================>....] - ETA: 56s - loss: 0.5753 - precision: 0.6934 - recall: 0.6915 - f1: 0.6836WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3650/4198 [=========================>....] - ETA: 55s - loss: 0.5751 - precision: 0.6936 - recall: 0.6915 - f1: 0.6837WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3660/4198 [=========================>....] - ETA: 54s - loss: 0.5751 - precision: 0.6937 - recall: 0.6915 - f1: 0.6837WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3670/4198 [=========================>....] - ETA: 53s - loss: 0.5749 - precision: 0.6940 - recall: 0.6916 - f1: 0.6839WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3680/4198 [=========================>....] - ETA: 52s - loss: 0.5747 - precision: 0.6939 - recall: 0.6919 - f1: 0.6840WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3690/4198 [=========================>....] - ETA: 51s - loss: 0.5746 - precision: 0.6940 - recall: 0.6918 - f1: 0.6840WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3700/4198 [=========================>....] - ETA: 50s - loss: 0.5746 - precision: 0.6939 - recall: 0.6915 - f1: 0.6838WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3710/4198 [=========================>....] - ETA: 49s - loss: 0.5743 - precision: 0.6942 - recall: 0.6916 - f1: 0.6840WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3720/4198 [=========================>....] - ETA: 48s - loss: 0.5742 - precision: 0.6941 - recall: 0.6917 - f1: 0.6840WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3730/4198 [=========================>....] - ETA: 47s - loss: 0.5740 - precision: 0.6943 - recall: 0.6917 - f1: 0.6841WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3740/4198 [=========================>....] - ETA: 46s - loss: 0.5739 - precision: 0.6944 - recall: 0.6917 - f1: 0.6842WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3750/4198 [=========================>....] - ETA: 45s - loss: 0.5737 - precision: 0.6944 - recall: 0.6916 - f1: 0.6841WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3760/4198 [=========================>....] - ETA: 44s - loss: 0.5738 - precision: 0.6944 - recall: 0.6915 - f1: 0.6840WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3770/4198 [=========================>....] - ETA: 43s - loss: 0.5737 - precision: 0.6946 - recall: 0.6916 - f1: 0.6842WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3780/4198 [==========================>...] - ETA: 42s - loss: 0.5737 - precision: 0.6946 - recall: 0.6917 - f1: 0.6842WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3790/4198 [==========================>...] - ETA: 41s - loss: 0.5737 - precision: 0.6946 - recall: 0.6918 - f1: 0.6843WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3800/4198 [==========================>...] - ETA: 40s - loss: 0.5735 - precision: 0.6946 - recall: 0.6919 - f1: 0.6844WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3810/4198 [==========================>...] - ETA: 39s - loss: 0.5733 - precision: 0.6948 - recall: 0.6920 - f1: 0.6845WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3820/4198 [==========================>...] - ETA: 38s - loss: 0.5732 - precision: 0.6948 - recall: 0.6920 - f1: 0.6845WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3830/4198 [==========================>...] - ETA: 37s - loss: 0.5732 - precision: 0.6948 - recall: 0.6919 - f1: 0.6845WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3840/4198 [==========================>...] - ETA: 36s - loss: 0.5730 - precision: 0.6949 - recall: 0.6921 - f1: 0.6847WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3850/4198 [==========================>...] - ETA: 35s - loss: 0.5728 - precision: 0.6951 - recall: 0.6921 - f1: 0.6848WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3860/4198 [==========================>...] - ETA: 34s - loss: 0.5727 - precision: 0.6952 - recall: 0.6922 - f1: 0.6849WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3870/4198 [==========================>...] - ETA: 33s - loss: 0.5726 - precision: 0.6952 - recall: 0.6923 - f1: 0.6849WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3880/4198 [==========================>...] - ETA: 32s - loss: 0.5725 - precision: 0.6953 - recall: 0.6923 - f1: 0.6850WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3890/4198 [==========================>...] - ETA: 31s - loss: 0.5725 - precision: 0.6953 - recall: 0.6924 - f1: 0.6850WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3900/4198 [==========================>...] - ETA: 30s - loss: 0.5725 - precision: 0.6953 - recall: 0.6924 - f1: 0.6850WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3910/4198 [==========================>...] - ETA: 29s - loss: 0.5724 - precision: 0.6955 - recall: 0.6926 - f1: 0.6852WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3920/4198 [===========================>..] - ETA: 28s - loss: 0.5722 - precision: 0.6956 - recall: 0.6926 - f1: 0.6853WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3930/4198 [===========================>..] - ETA: 27s - loss: 0.5721 - precision: 0.6956 - recall: 0.6927 - f1: 0.6853WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3940/4198 [===========================>..] - ETA: 26s - loss: 0.5720 - precision: 0.6956 - recall: 0.6929 - f1: 0.6855WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3950/4198 [===========================>..] - ETA: 25s - loss: 0.5718 - precision: 0.6957 - recall: 0.6928 - f1: 0.6855WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3960/4198 [===========================>..] - ETA: 24s - loss: 0.5717 - precision: 0.6958 - recall: 0.6929 - f1: 0.6856WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3970/4198 [===========================>..] - ETA: 23s - loss: 0.5718 - precision: 0.6959 - recall: 0.6927 - f1: 0.6855WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3980/4198 [===========================>..] - ETA: 22s - loss: 0.5717 - precision: 0.6959 - recall: 0.6928 - f1: 0.6855WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "3990/4198 [===========================>..] - ETA: 21s - loss: 0.5716 - precision: 0.6961 - recall: 0.6929 - f1: 0.6857WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4000/4198 [===========================>..] - ETA: 20s - loss: 0.5714 - precision: 0.6962 - recall: 0.6929 - f1: 0.6858WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4010/4198 [===========================>..] - ETA: 19s - loss: 0.5712 - precision: 0.6964 - recall: 0.6932 - f1: 0.6860WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4020/4198 [===========================>..] - ETA: 18s - loss: 0.5711 - precision: 0.6965 - recall: 0.6934 - f1: 0.6862WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4030/4198 [===========================>..] - ETA: 17s - loss: 0.5710 - precision: 0.6967 - recall: 0.6936 - f1: 0.6863WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4040/4198 [===========================>..] - ETA: 16s - loss: 0.5708 - precision: 0.6968 - recall: 0.6937 - f1: 0.6865WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4050/4198 [===========================>..] - ETA: 15s - loss: 0.5706 - precision: 0.6970 - recall: 0.6938 - f1: 0.6866WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4060/4198 [============================>.] - ETA: 14s - loss: 0.5706 - precision: 0.6968 - recall: 0.6939 - f1: 0.6866WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4070/4198 [============================>.] - ETA: 13s - loss: 0.5705 - precision: 0.6968 - recall: 0.6940 - f1: 0.6866WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4080/4198 [============================>.] - ETA: 12s - loss: 0.5704 - precision: 0.6968 - recall: 0.6938 - f1: 0.6866WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4090/4198 [============================>.] - ETA: 11s - loss: 0.5704 - precision: 0.6969 - recall: 0.6938 - f1: 0.6866WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4100/4198 [============================>.] - ETA: 10s - loss: 0.5702 - precision: 0.6969 - recall: 0.6939 - f1: 0.6867WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4110/4198 [============================>.] - ETA: 8s - loss: 0.5701 - precision: 0.6971 - recall: 0.6938 - f1: 0.6867WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4120/4198 [============================>.] - ETA: 7s - loss: 0.5701 - precision: 0.6972 - recall: 0.6939 - f1: 0.6868WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4130/4198 [============================>.] - ETA: 6s - loss: 0.5699 - precision: 0.6973 - recall: 0.6940 - f1: 0.6869WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4140/4198 [============================>.] - ETA: 5s - loss: 0.5697 - precision: 0.6976 - recall: 0.6942 - f1: 0.6871WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4150/4198 [============================>.] - ETA: 4s - loss: 0.5696 - precision: 0.6976 - recall: 0.6942 - f1: 0.6872WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4160/4198 [============================>.] - ETA: 3s - loss: 0.5695 - precision: 0.6976 - recall: 0.6943 - f1: 0.6872WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4170/4198 [============================>.] - ETA: 2s - loss: 0.5694 - precision: 0.6976 - recall: 0.6945 - f1: 0.6873WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4180/4198 [============================>.] - ETA: 1s - loss: 0.5694 - precision: 0.6976 - recall: 0.6946 - f1: 0.6874WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4190/4198 [============================>.] - ETA: 0s - loss: 0.5693 - precision: 0.6976 - recall: 0.6948 - f1: 0.6875WARNING:tensorflow:Can save best model only with val_f1 available, skipping.\n",
            "4198/4198 [==============================] - 454s 107ms/step - loss: 0.5691 - precision: 0.6976 - recall: 0.6947 - f1: 0.6875 - val_loss: 0.4981 - val_precision: 0.7705 - val_recall: 0.7175 - val_f1: 0.7363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy_lTyDFU3cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "869f4fca-d1aa-4ce8-a596-1e1117b4255c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "\n",
        "def plot_metrix(ax, x1, x2, title):\n",
        "    ax.plot(range(1, len(x1) + 1), x1, label='train')\n",
        "    ax.plot(range(1, len(x2) + 1), x2, label='val')\n",
        "    ax.set_ylabel(title)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.legend()\n",
        "    ax.margins(0)\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(16, 9))\n",
        "    ax1, ax2, ax3, ax4 = axes.ravel()\n",
        "\n",
        "    plot_metrix(ax1, history.history['precision'], history.history['val_precision'], 'Precision')\n",
        "    plot_metrix(ax2, history.history['recall'], history.history['val_recall'], 'Recall')\n",
        "    plot_metrix(ax3, history.history['f1'], history.history['val_f1'], \"$F_1$\")\n",
        "    plot_metrix(ax4, history.history['loss'], history.history['val_loss'], 'Loss')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7sAAAIcCAYAAAA39LkUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf3QU9b3/8dcmGxIgGNjdmpASpQSiYgghXTEnchFIar1VKRcUvq1QkbRitcq91irxcqVqY6NAtT/wF42kaGtTvVpL25yj0VJ11ypKgzUgEI1akkCSXRqSQBI2s98/vG7dJoGE3eyvPB/neM7OzGdm3/OG45v3zmdmTF6v1ysAAAAAAGJIXLgDAAAAAAAg2Gh2AQAAAAAxh2YXAAAAABBzaHYBAAAAADGHZhcAAAAAEHNodgEAAAAAMccc6i+sqanR1q1bZRiGCgsLtWjRIr/tFRUVqq2tlST19PSora1NFRUVevfdd/WLX/zCN66xsVFr1qzR7NmzQxo/AAAAACDymUL5nl3DMLRmzRqtW7dOVqtVJSUlWrNmjSZNmtTv+KqqKtXX1+uGG27wW9/R0aGbbrpJjzzyiBITE0MROgAAAAAgioR0GnNdXZ3S0tKUmpoqs9msgoIC7dy5c8DxDodDc+bM6bP+L3/5i2bNmkWjCwAAAADoV0ibXbfbLavV6lu2Wq1yu939jm1paVFzc7Oys7P7bHM4HLrooouGLU4AAAAAQHQL+T27g+VwOJSfn6+4OP9+/MiRI/r44481c+bMAfetrq5WdXW1JKmsrEw9PT3DGmsgzGazPB5PuMOIauQwcOQwOMhj4CI9h6NGjQp3CDGjsbEx3CEMyGazqbW1NdxhRDVyGDhyGBzkMXCRnsP09PQBt4W02bVYLHK5XL5ll8sli8XS71in06ni4uI+619//XXNnj1bZvPAoRcVFamoqMi3HMl/OJH+lycakMPAkcPgII+Bi/QcnqygAgCAyBLSacyZmZlqampSc3OzPB6PnE6n7HZ7n3ENDQ3q7OxUVlZWn21MYQYAAAAAnEpIr+zGx8dr1apVKi0tlWEYmj9/vjIyMlRZWanMzExf4+twOFRQUCCTyeS3f3Nzs1pbWzV9+vRQhg0AAAAAiDIhffVQuHBfUGwjh4Ejh8ExEvLo9XrV1dUlwzD6/CAZDImJieru7g76cYfC6/UqLi5OSUlJfc6RaczBQ22ObeQwcOQwOEZCHqnNEXLPLgAgunV1dSkhIeGkz00IhNlsVnx8/LAceyg8Ho+6uro0evTocIcCAMBJUZsHFtJ7dgEA0c0wjGErppHEbDbLMIxwhwEAwClRmwdGswsAGLThmB4VqUbSuQIAotdIqldDPVeaXQBA1Ghra1NFRcWQ91uxYoXa2tqCHxAAACNcJNdmml0AQNQ4evSotm3b1me9x+M56X5PPPGEUlJShissAABGrEiuzbE/uRsAEDPuvfdeffTRR/rSl76khIQEJSYmKiUlRXV1dXrttde0atUqNTY2qru7W8XFxVq+fLkk6cILL1RVVZU6Ozu1fPlyzZ49W2+99ZbS0tL0+OOP8yAqAABOUyTXZppdAMBpMX69Rd6/1wf3oGdnSkuLB9x8xx13aN++fXrxxRfldDr1jW98Qy+//LLOOussSdKmTZs0YcIEHT9+XJdddpm+8pWvyGKx+B2jvr5emzdv1oYNG7R69Wr98Y9/1JIlS4J7HgAAhAG12R/NLgAgauXm5vqKqSQ9/vjjqqqqkvTJe1zr6+v7FNSMjAxlZ2dLknJycvT3v/89dAEDABDjIqk20+wCAE5L3P/7VtCPaTabT3mPz2eNGTPG99npdOrVV1/V9u3bNXr0aF155ZXq7u7us09iYqLvc3x8vLq6ugILGgCACEFt9scDqgAAUWPs2LHq6Ojod1t7e7tSUlI0evRo1dXVadeuXSGODgCAkSeSazNXdgEAUcNiseiCCy7QggULlJSUJJvN5ts2b948PfHEE7r44ouVmZmpvLy8MEYKAMDIEMm12eT1er0h/cYwaGxsDHcIA7LZbGptbQ13GFGNHAaOHAbHSMjjsWPH/KYnBdtQp0oNp/7ONT09PUzRxB5qc2wjh4Ejh8ExEvJIbR64NjONGQAAAAAQc2h2AQAAAAAxh3t2AQAYIWpqarR161YZhqHCwkItWrTIb3tFRYVqa2slST09PWpra1NFRYUkqbS0VAcOHNC5556rtWvX+vbZvHmz9uzZ45tWduONN2ry5MkhOR8AAE6GZhcAgBHAMAyVl5dr3bp1slqtKikpkd1u16RJk3xjVq5c6ftcVVWl+vp63/LChQvV3d2t6urqPsdesWKF8vPzhzV+AACGimnMAACMAHV1dUpLS1NqaqrMZrMKCgq0c+fOAcc7HA7NmTPHtzxjxgyNHj06FKECABAUNLsAAIwAbrdbVqvVt2y1WuV2u/sd29LSoubmZmVnZw/q2E899ZRuvfVWVVRU6MSJE0GJFwCAQDGNGQAQs6ZNm6YDBw6EO4yo43A4lJ+fr7i4U/8m/vWvf13jx4+Xx+PRo48+queff15XXnlln3HV1dW+KdBlZWV+72GMNGazOaLjiwbkMHDkMDhGQh4PHz4ss3l427pgHv8LX/iC320yQ5GYmDikP0+aXQAARgCLxSKXy+Vbdrlcslgs/Y51Op0qLi4e1HEnTJggSUpISND8+fO1ffv2fscVFRWpqKjItxzJ770cCe/lHG7kMHDkMDhGQh67u7sVHx8/bMcfjvfsnu7xuru7+/x5nuw9uzS7AICoce+99yo9Pd33IKVNmzYpPj5eTqdTbW1t8ng8uu222/TlL385vIFGoMzMTDU1Nam5uVkWi0VOp1M333xzn3ENDQ3q7OxUVlbWoI575MgRTZgwQV6vVzt37lRGRkawQwcARLBIrs00uwCA0/Lztw6r/khXUI+ZaR2jVXmfG3D7woULtX79el9B3b59u375y1+quLhY48aNk9vt1hVXXKFLLrlEJpMpqLFFu/j4eK1atUqlpaUyDEPz589XRkaGKisrlZmZKbvdLumTKcwFBQV98nfnnXeqoaFBXV1duv7663X99dcrNzdXP/nJT3T06FFJ0tlnn63rrrsu5OcGAPgEtdlfyJvdQN7x19raqkceecQ3DaukpERnnnlmSOMHAIRPdna2WltbdejQIblcLqWkpOjMM8/U97//fb3xxhsymUw6dOiQWlpaqA/9yMvLU15ent+6ZcuW+S0vXbq0333vvvvuftevX78+OMEBAKJSJNfmkDa7gb7j72c/+5kWL16snJwcdXV18as9AITRN+2pQT/mYO4Luvzyy/WHP/xBzc3NWrhwoZ599lm5XC5VVVUpISFBF154obq7u4MeGwAAkY7a7C+krx4K5B1/Bw8eVG9vr3JyciRJSUlJSkxMDEncAIDIsXDhQj3//PP6wx/+oMsvv1zt7e2y2WxKSEiQw+HQwYMHwx0iAAAjSqTW5pBe2e3vHX8DvRLiX9/x19jYqLFjx2rjxo1qbm7WjBkzdPXVV/f7WgRebzCykMPAkcPgGAl5jITXG5x//vnq7OzUxIkT9fnPf15XXXWVVqxYocLCQuXm5mratGmKj4/3Hed04x3q6w0AABipzjnnHHV2dvoubC5evFjXXHONCgsLlZOTo6lTp4Ylroh9QNW/vuPPMAzt3btX999/v2w2mx544AHt2LFDCxYs6LMvrzcYWchh4MhhcIyEPEbK6w1eeuklSZ+8uiAlJUW/+93v+ozxeDw6cOBAyF5vAADASPZpbZY+ed3dQK+iG+hi53AI6TTmob7j76KLLvLbd/LkyUpNTVV8fLxmz56tDz74YNhjBgAAAABEn5A2u599x5/H45HT6fS96uCz+nvH39SpU3Xs2DHf6w3effddvwdbAQAAAADwqZBOYw7kHX9xcXFasWKF7r77bnm9Xk2ZMsVvqjIAAAAAAJ8K+T27gbzjLycnRxs3bhy22AAAJ+f1esMdQsiMpHMFAESvkVSvhnquIZ3GDACIbnFxcaf9wKdo4vF4+n3aPwAAkYbaPLCIfRozACDyJCUlqaurS93d3X63mgRLYmJiWF46/1ler1dxcXFKSkoKaxwAAAwGtXlgNLsAgEEzmUwaPXr0sB1/JLy+CQCAYKI2D4w5WgAAAACAmEOzCwAAAACIOTS7AAAAAICYQ7MLAAAAAIg5NLsAAAAAgJhDswsAAAAAiDk0uwAAAACAmEOzCwAAAACIOTS7AAAAAICYQ7MLAAAAAIg5NLsAAAAAgJhDswsAAAAAiDk0uwAAAACAmEOzCwAAAACIOTS7AAAAAICYQ7MLAAAAAIg5NLsAAAAAgJhDswsAAAAAiDnmUH9hTU2Ntm7dKsMwVFhYqEWLFvltr6ioUG1trSSpp6dHbW1tqqiokCQtW7ZMZ511liTJZrPp9ttvD2nsAAAAAIDoENJm1zAMlZeXa926dbJarSopKZHdbtekSZN8Y1auXOn7XFVVpfr6et/yqFGjtGHDhlCGDAAAAACIQiGdxlxXV6e0tDSlpqbKbDaroKBAO3fuHHC8w+HQnDlzQhghAAAAACAWhPTKrtvtltVq9S1brVYdOHCg37EtLS1qbm5Wdna2b92JEye0du1axcfH66tf/apmz5497DEDAAAAAKJPyO/ZHSyHw6H8/HzFxf3z4vNDDz0ki8Wiw4cP6+6779ZZZ52ltLS0PvtWV1erurpaklRWViabzRayuIfKbDZHdHzRgBwGjhwGB3kMHDkEAADBEtJm12KxyOVy+ZZdLpcsFku/Y51Op4qLi/vsL0mpqamaPn26Pvzww36b3aKiIhUVFfmWW1tbgxH+sLDZbBEdXzQgh4Ejh8FBHgMX6TlMT08PdwgAAGCQQnrPbmZmppqamtTc3CyPxyOn0ym73d5nXENDgzo7O5WVleVb19HRoRMnTkiSjh49qn379vk92AoAAAAAgE+F9MpufHy8Vq1apdLSUhmGofnz5ysjI0OVlZXKzMz0Nb4Oh0MFBQUymUy+fRsaGvTYY48pLi5OhmFo0aJFNLsAAAAAgH6F/J7dvLw85eXl+a1btmyZ3/LSpUv77HfOOedo06ZNwxobAAAAACA2hHQaMwAAAAAAoUCzCwAAAACIORH76iEAABBcNTU12rp1qwzDUGFhoRYtWuS3vaKiQrW1tZKknp4etbW1qaKiQpJUWlqqAwcO6Nxzz9XatWt9+zQ3N+vBBx9Ue3u7pkyZoptuuklmM/+8AACEH9UIAIARwDAMlZeXa926dbJarSopKZHdbvd72OPKlSt9n6uqqlRfX+9bXrhwobq7u33vsf/Uk08+qcsuu0wXXXSRHnvsMb388su65JJLhv18AAA4FaYxAwAwAtTV1SktLU2pqakym80qKCjQzp07BxzvcDg0Z84c3/KMGTM0evRovzFer1e1tbXKz8+XJM2bN++kxwQAIJRodgEAGAHcbresVqtv2Wq1yu129zu2paVFzc3Nys7OPukx29vbNWbMGMXHx0uSLBbLgMcEACDUmMYMAAD8OBwO5efnKy4ueL+JV1dX+6ZAl5WVyWazBe3YwWY2myM6vmhADgNHDoODPAYumnNIswsAwAhgsVjkcrl8yy6XSxaLpd+xTqdTxcXFpzzmuHHjdOzYMfX29io+Pl5ut3vAYxYVFamoqMi33NraOsQzCB2bzRbR8UUDchg4chgc5DFwkZ7D9PT0AbcxjRkAgBEgMzNTTU1Nam5ulsfjkdPplN1u7zOuoaFBnZ2dysrKOuUxTSaTzj//fP3lL3+RJO3YsaPfYwIAEA5c2QUAYASIj4/XqlWrVFpaKsMwNH/+fGVkZKiyslKZmZm+JtXhcKigoEAmk8lv/zvvvFMNDQ3q6urS9ddfr+uvv165ubm6+uqr9eCDD+rXv/61vvCFL2jBggXhOD0AAPoweb1eb7iDGG6NjY3hDmFAkT4tIBqQw8CRw+Agj4GL9ByebKoUhobaHNvIYeDIYXCQx8BFeg6ZxgwAAAAAGFFodgEAAAAAMYdmFwAAAAAQc2h2AQAAAAAxh2YXAAAAABBzaHYBAAAAADGHZhcAAAAAEHNodgEAAAAAMYdmFwAAAAAQc2h2AQAAAAAxx3w6O+3evVsffvihurq6/NYvW7YsKEEBAAAAABCIITe75eXlev3113X++ecrMTFxyF9YU1OjrVu3yjAMFRYWatGiRX7bKyoqVFtbK0nq6elRW1ubKioqfNuPHTumW265RRdccIGKi4uH/P0AAAAAgNg35Gb3tdde04YNG2Sz2Yb8ZYZhqLy8XOvWrZPValVJSYnsdrsmTZrkG7Ny5Urf56qqKtXX1/sdo7KyUuedd96QvxsAAAAAMHIM+Z7dM844Q2PHjj2tL6urq1NaWppSU1NlNptVUFCgnTt3Djje4XBozpw5vuUPPvhAbW1tmjlz5ml9PwAAAABgZBhys3v55ZfrJz/5ifbv36/Dhw/7/XcqbrdbVqvVt2y1WuV2u/sd29LSoubmZmVnZ0v65Krwtm3btGLFiqGGDAAAAAAYYYY8jfnnP/+5JGnXrl19tlVWVgYe0f9xOBzKz89XXNwn/fgLL7ygWbNm+TXLA6murlZ1dbUkqays7LSmXIeK2WyO6PiiATkMHDkMDvIYOHIIAACCZcjNbiANrcVikcvl8i27XC5ZLJZ+xzqdTr8HUO3fv1979+7VCy+8oK6uLnk8HiUlJenqq6/us29RUZGKiop8y62tracd83Cz2WwRHV80IIeBI4fBQR4DF+k5TE9PD3cIAABgkE7r1UPSJw2k2+2WxWIZ9K/wmZmZampqUnNzsywWi5xOp26++eY+4xoaGtTZ2amsrCzfus+O27Fjh95///1+G10AAAAAAIbc7B45ckQPPvig9u/fr3Hjxqm9vV1ZWVlas2bNgFdpPxUfH69Vq1aptLRUhmFo/vz5ysjIUGVlpTIzM2W32yV9MoW5oKBAJpPp9M4KAAAAADCiDbnZ3bJli84++2yVlJQoKSlJXV1deuqpp7Rlyxbdfvvtp9w/Ly9PeXl5fuuWLVvmt7x06dKTHmPevHmaN2/eUEMHACDq3HnnnYP68feuu+4KQTQAAESPITe7+/bt0y233CKz+ZNdk5KStHz5cl1//fVBDw4AgJFuwYIF4Q4BAICoNORmd+zYsTp48KAmT57sW9fY2KgxY8YEMy4AACAxkwkAgNM05GZ34cKFuueee7RgwQJ97nOfU0tLi3bs2NFnKjIAAAjcyy+/PKhxXAEGAMDfkJvdoqIipaWl6bXXXtPHH3+sCRMm6Oabb9aMGTOGIz4AAEa0V199dVDjaHYBAPB3Wq8eys7OVnZ2drBjAQAA/2L9+vXhDgEAgKg0qGb32Wef1eLFiyVJlZWVA45jKjMAAKHh9Xrl9Xp9y3FxcWGMBgCAyDOoZtflcvX7GQAAhI7b7VZ5ebn27t2rzs5Ov20n+zEaAICRaFDN7re+9S3f5xtuuGHYggEAAAN77LHHlJiYqDvvvFPr16/XXXfdpaefflqzZs0Kd2gAAEScIc95OnjwoP7xj39Ikrq6uvSb3/xGTz/9tLq7u4MeHAAA+Kf9+/fr29/+tiZPniyTyaTJkyfr29/+tn7/+9+HOzQAACLOkJvdH//4xzp27Jgkadu2bdq7d68OHDigxx57LOjBAQCAf4qLi1N8fLykT957f/ToUSUmJsrtdoc5MgAAIs+Qn8bc3Nys9PR0eb1evfnmm/rRj36kUaNG6Tvf+c5wxAcAAP7P1KlT9de//lWzZ8/WzJkz9cADD2jUqFHKzMwMd2gAAEScITe7o0aN0vHjx3Xw4EHZbDadccYZ6u3t1YkTJ4YjPgAA8H9uuukm3xOYV65cqe3bt+v48eO67LLLwhwZAACRZ8jN7kUXXaS7775bx48f16WXXipJqq+v15lnnhn04AAAwD+NHTvW93nUqFFasmRJGKMBACCyDbnZXblypXbv3q34+HhlZ2dLkkwmk6655pqgBwcAAP5p48aNuuyyy3Teeef51u3du1d//OMf9d3vfjeMkQEAEHmG3OxK0syZM/2WuVcIAIDht2fPHt1yyy1+66ZNm6ba2towRQQAQOQaVLNbWlqq//7v/5Yk3XnnnTKZTP2Ou+uuu4IXGQAA8JOQkKCuri6NGTPGt667u9v3hGYAAPBPg2p2L774Yt/nBQsWDFswAABgYDNnztRjjz2m6667TmPGjNGxY8dUXl6u3NzccIcGAEDEGVSzO2fOHN/nefPmDVcsAADgJL7xjW/opz/9qa699lqNGzdOHR0dys3N1U033RTu0AAAiDhDvmf38ccf10UXXaRzzjnHt27fvn16/fXXtXLlymDGBgAAPiM5OVklJSX6xz/+odbWVtlsNo0fPz7cYQEAEJHihrqDw+Ho80CqKVOm6LXXXgtaUAAAoH/t7e165513VFtbq/Hjx8vtdsvlcoU7LAAAIs6Qr+yaTCYZhuG3zjAM30vuAQDA8NizZ482bdqkKVOmaN++ffrqV7+qQ4cO6Xe/+53Wrl17yv1ramq0detWGYahwsJCLVq0yG97RUWF78nOPT09amtrU0VFhSRpx44devbZZyVJixcv9t3W9P3vf19HjhzRqFGjJEnr1q1TSkpKkM4YAIDTN+Rm99xzz9Wvf/1rLV++XHFxcTIMQ08//bTOPffcQe1/uoW2paVFGzdulGEY6u3t1aWXXqpLLrlkqOEDABC1Kioq9J//+Z+aMWOGrr32WknS1KlT9f77759yX8MwVF5ernXr1slqtaqkpER2u12TJk3yjfns7UhVVVWqr6+XJHV0dOiZZ55RWVmZJGnt2rWy2+1KTk6WJN188828hhAAEHGG3Oxee+21Kisr0+rVq2Wz2dTa2qoJEybo9ttvP+W+gRTaCRMm6Ac/+IHvtQvf/e53ZbfbZbFYhnoKAABEpZaWFs2YMcNvndlsVm9v7yn3raurU1pamlJTUyVJBQUF2rlzp18N/iyHw6GlS5dK+uSH6pycHF9zm5OTo5qaGr8HWAIAEGmG3OxarVbdd999qqurk8vlktVq1dSpUxUXd+rbfwMptGbzP0M9ceJEn6nUAADEukmTJqmmpsbvVUN/+9vfdNZZZ51yX7fbLavV6lu2Wq06cOBAv2NbWlrU3Nys7Ozsfve1WCxyu92+5YceekhxcXG68MILtWTJEplMpj7HrK6uVnV1tSSprKxMNpvtlDGHi9lsjuj4ogE5DBw5DA7yGLhozuGQm11JvqnEXq9XWVlZ6urqkiQlJSWddL9ACq0ktba2qqysTIcOHdLy5cu5qgsAGFFWrFih++67T7NmzVJPT48ee+wxvf322/re974X1O9xOBzKz88f1A/ZN998sywWi44fP65NmzbplVde0cUXX9xnXFFRkYqKinzLra2tQY05mD6duYbTRw4DRw6DgzwGLtJzmJ6ePuC2ITe7H3/8se677z4lJCTI5XKpoKBAe/bs0Z///Gf913/9V0CBflZ/hdZms2njxo1yu93asGGD8vPz+33lAr8ejyzkMHDkMDjIY+DI4cllZWVpw4YNevXVV5WUlCSbzaY1a9bod7/7nW655ZaT7muxWPye2uxyuQb80djpdKq4uNhv3z179viW3W63pk+f7tsmSaNHj9acOXNUV1fXb7MLAECoDbnZ3bJli5YtW6a5c+f6Ho4xffp0Pfroo6fcN5BC+6/HycjI0Hvvvaf8/Pw+2/n1eGQhh4Ejh8FBHgMX6Tk82a/Hw6m7u1vPPfecPvzwQ02cOFFXXXWVjh49qieeeELPPvus5s6de8pjZGZmqqmpSc3NzbJYLHI6nbr55pv7jGtoaFBnZ6eysrJ863Jzc/XUU0+po6NDkrR79259/etfV29vrzo7O3XGGWfI4/Ho7bff7nNPMQAA4TLkZvfgwYP6t3/7N791SUlJ6unpOeW+gRRal8ulcePGadSoUero6NC+fft0+eWXDzV8AACiTnl5uerr6zVz5kzV1NTo448/VmNjoy6++GKtXr1aZ5xxximPER8fr1WrVqm0tFSGYWj+/PnKyMhQZWWlMjMzZbfbJX0ys6qgoMDvvtvk5GQtWbJEJSUlkqQrr7xSycnJ6urqUmlpqXp7e2UYhmbMmOH3YzMAAOE05Gb3c5/7nD744AO/Vwx8+uCpUwmk0DY0NGjbtm0ymUzyer264oorBvVADgAAot3u3bt1//33KyUlRf/+7/+uG264QevXr/dNJR6svLw85eXl+a1btmyZ3/KnD4b8VwsWLNCCBQv81iUlJem+++4bUgwAAITKkJvdZcuWqaysTF/60pfk8Xj03HPP6cUXX9Tq1asHtf/pFtqcnBxt3LhxqOECABD1urq6lJKSIumThzsmJSUNudEFAGCkGXKz+8UvflF33HGHXnrpJU2fPl0tLS269dZbNWXKlOGIDwCAEa+3t1fvvvuu37p/Xf7s2wsAAMAQm13DMLRmzRr96Ec/0je/+c3higkAAHxGSkqKHn74Yd9ycnKy37LJZNLPfvazcIQGAEDEGlKzGxcXp7i4OJ04cUIJCQnDFRMAAPiMzZs3hzsEAACizpCnMX/lK1/RAw88oP/4j/+QxWLxe4hUampqUIMDAAAAAOB0DLnZffzxxyVJ77zzTp9tlZWVgUcEAAAAAECABt3sdnd363//9381a9YsTZkyRYsWLdKoUaOGMzYAAAAAAE5L3GAHlpeX6+2339akSZP0xhtv6MknnxzOuAAAAAAAOG2DbnZramq0bt06LV++XCUlJXr77beHMy4AAAAAAE7boJvd7u5uTZgwQZJks9l07NixYQsKAAAAAIBADPqe3X99ob1hGLzQHgAAAAAQkQbd7PJCewAAAABAtBh0s8sL7QEAAAAA0WLQ9+wCAAAAABAtaHYBAAAAADGHZhcAAAAAEHNodgEAAAAAMYdmFwAAAAAQc2h2AQAAAAAxh2YXAAAAABBzaHYBAAAAADGHZhcAAAAAEHNodgEAAAAAMccc6i+sqanR1q1bZRiGCgsLtWjRIr/tFRUVqq2tlST19PSora1NFRUV+vDDD7VlyxYdP35ccXFxWrx4sQoKCtCUWYEAACAASURBVEIdPgAAAAAgCoS02TUMQ+Xl5Vq3bp2sVqtKSkpkt9s1adIk35iVK1f6PldVVam+vl6SNGrUKH3nO9/RxIkT5Xa7tXbtWs2cOVNjx44N5SkAAAAAAKJASKcx19XVKS0tTampqTKbzSooKNDOnTsHHO9wODRnzhxJUnp6uiZOnChJslgsSklJ0dGjR0MSNwAAAAAguoS02XW73bJarb5lq9Uqt9vd79iWlhY1NzcrOzu7z7a6ujp5PB6lpqYOW6wAAAAAgOgV8nt2B8vhcCg/P19xcf79+JEjR/TTn/5UN954Y59tn6qurlZ1dbUkqaysTDabbdjjPV1mszmi44sG5DBw5DA4yGPgyCEAAAiWkDa7FotFLpfLt+xyuWSxWPod63Q6VVxc7Lfu2LFjKisr09e+9jVlZWUN+D1FRUUqKiryLbe2tgYY+fCx2WwRHV80IIeBI4fBQR4DF+k5TE9PD3cIAABgkEI6jTkzM1NNTU1qbm6Wx+OR0+mU3W7vM66hoUGdnZ1+Da3H49HGjRs1d+5c5efnhzJsAAAAAECUCemV3fj4eK1atUqlpaUyDEPz589XRkaGKisrlZmZ6Wt8HQ6HCgoKZDKZfPs6nU7t3btX7e3t2rFjhyTpxhtv1OTJk0N5CgAAAACAKBDye3bz8vKUl5fnt27ZsmV+y0uXLu2z39y5czV37txhjQ0AAAAAEBtCOo0ZAAAAAIBQoNkFAAAAAMQcml0AAAAAQMyh2QUAAAAAxByaXQAAAABAzKHZBQAAAADEHJpdAAAAAEDMCfl7dgEAQHjU1NRo69atMgxDhYWFWrRokd/2iooK1dbWSpJ6enrU1tamiooKSdKOHTv07LPPSpIWL16sefPmSZI++OADbd68WT09PZo1a5auvfZamUymkJ0TAAADodkFAGAEMAxD5eXlWrdunaxWq0pKSmS32zVp0iTfmJUrV/o+V1VVqb6+XpLU0dGhZ555RmVlZZKktWvXym63Kzk5WVu2bNHq1as1bdo0/fCHP1RNTY1mzZoV0nMDAKA/TGMGAGAEqKurU1pamlJTU2U2m1VQUKCdO3cOON7hcGjOnDmSPrkinJOTo+TkZCUnJysnJ0c1NTU6cuSIjh8/rqysLJlMJs2dO/ekxwQAIJRodgEAGAHcbresVqtv2Wq1yu129zu2paVFzc3Nys7O7ndfi8Uit9s9pGMCABBqTGMGAAB+HA6H8vPzFRcXvN/Eq6urVV1dLUkqKyuTzWYL2rGDzWw2R3R80YAcBo4cBgd5DFw055BmFwCAEcBiscjlcvmWXS6XLBZLv2OdTqeKi4v99t2zZ49v2e12a/r06UM6ZlFRkYqKinzLra2tp30uw81ms0V0fNGAHAaOHAYHeQxcpOcwPT19wG1MYwYAYATIzMxUU1OTmpub5fF45HQ6Zbfb+4xraGhQZ2ensrKyfOtyc3O1e/dudXR0qKOjQ7t371Zubq4mTJig0aNHa//+/fJ6vXrllVf6PSYAAOHAlV0AAEaA+Ph4rVq1SqWlpTIMQ/Pnz1dGRoYqKyuVmZnpa1IdDocKCgr8Xh+UnJysJUuWqKSkRJJ05ZVXKjk5WZL0zW9+Uw899JB6enqUm5vLk5gBABHD5PV6veEOYrg1NjaGO4QBRfq0gGhADgNHDoODPAYu0nN4sqlSGBpqc2wjh4Ejh8FBHgMX6TlkGjMAAAAAYESh2QUAAAAAxByaXQAAAABAzKHZBQAAAADEHJpdAAAAAEDMCfmrh2pqarR161YZhqHCwkItWrTIb3tFRYVqa2slST09PWpra1NFRYUkqbS0VAcOHNC5556rtWvXhjp0AAAAAECUCGmzaxiGysvLtW7dOlmtVpWUlMhut2vSpEm+MStXrvR9rqqqUn19vW954cKF6u7uVnV1dSjDBgAAAABEmZBOY66rq1NaWppSU1NlNptVUFCgnTt3Djje4XBozpw5vuUZM2Zo9OjRoQgVAAAAABDFQtrsut1uWa1W37LVapXb7e53bEtLi5qbm5WdnR2q8AAAAAAAMSLk9+wOlsPhUH5+vuLiht6PV1dX+6Y6l5WVyWazBTu8oDGbzREdXzQgh4Ejh8FBHgNHDgEAQLCEtNm1WCxyuVy+ZZfLJYvF0u9Yp9Op4uLi0/qeoqIiFRUV+ZZbW1tP6zihYLPZIjq+aEAOA0cOg4M8Bi7Sc5ienh7uEAAAwCCFdBpzZmammpqa1NzcLI/HI6fTKbvd3mdcQ0ODOjs7lZWVFcrwAAAAAAAxIqRXduPj47Vq1SqVlpbKMAzNnz9fGRkZqqysVGZmpq/xdTgcKigokMlk8tv/zjvvVENDg7q6unT99dfr+uuvV25ubihPAQAAAAAQBUJ+z25eXp7y8vL81i1btsxveenSpf3ue/fddw9bXAAAAACA2BHSacwAAAAAAIQCzS4AAAAAIObQ7AIAAAAAYg7NLgAAAAAg5tDsAgAAAABiDs0uAAAAACDm0OwCAAAAAGIOzS4AAAAAIObQ7AIAAAAAYg7NLgAAAAAg5tDsAgAAAABiDs0uAAAAACDm0OwCAAAAAGIOzS4AAAAAIObQ7AIAAAAAYg7NLgAAAAAg5tDsAgAAAABiDs0uAAAAACDm0OwCAAAAAGIOzS4AAAAAIObQ7AIAAAAAYg7NLgAAAAAg5phD/YU1NTXaunWrDMNQYWGhFi1a5Le9oqJCtbW1kqSenh61tbWpoqJCkrRjxw49++yzkqTFixdr3rx5oQwdAAAAABAlQtrsGoah8vJyrVu3TlarVSUlJbLb7Zo0aZJvzMqVK32fq6qqVF9fL0nq6OjQM888o7KyMknS2rVrZbfblZycHMpTAAAAAABEgZBOY66rq1NaWppSU1NlNptVUFCgnTt3Djje4XBozpw5kj65IpyTk6Pk5GQlJycrJydHNTU1oQodAAAAABBFQtrsut1uWa1W37LVapXb7e53bEtLi5qbm5Wdnd3vvhaLZcB9AQAAAAAjW8jv2R0sh8Oh/Px8xcUNvR+vrq5WdXW1JKmsrEw2my3Y4QWN2WyO6PiiATkMHDkMDvIYOHI4vE713AxJcjqdevrpp2UymXT22WdrzZo1kqQnn3xSf/3rXyVJS5YsUUFBgSRp8+bN2rNnj8aMGSNJuvHGGzV58uTQnBAAACcR0mbXYrHI5XL5ll0ulywWS79jnU6niouL/fbds2ePb9ntdmv69On97ltUVKSioiLfcmtra6ChDxubzRbR8UUDchg4chgc5DFwkZ7D9PT0cIdw2gbz3Iympib99re/1T333KPk5GS1tbVJknbt2qX6+nrdf//9OnHihO666y7l5ub6GtwVK1YoPz8/LOcFAMBAQjqNOTMzU01NTWpubpbH45HT6ZTdbu8zrqGhQZ2dncrKyvKty83N1e7du9XR0aGOjg7t3r1bubm5oQwfAICoNZjnZrz00kv68pe/7Hv4Y0pKiiTp4MGDOu+88xQfH6+kpCSdddZZPDcDABDxQnplNz4+XqtWrVJpaakMw9D8+fOVkZGhyspKZWZm+hpfh8OhgoICmUwm377JyclasmSJSkpKJElXXnklT2IGAGCQ+ntuxoEDB/zGNDY2SpL+53/+R4Zh6KqrrlJubq7OPvtsPfPMM7riiivU3d2t2tpavyvCTz31lJ555hllZ2fr6quvVkJCQmhOCgCAkwj5Pbt5eXnKy8vzW7ds2TK/5aVLl/a774IFC7RgwYJhiw0AgJHMMAw1NTVp/fr1crvdWr9+vTZu3KiZM2fq/fff17p163TGGWcoKyvL90yNr3/96xo/frw8Ho8effRRPf/887ryyiv7HJvnaYws5DBw5DA4yGPgojmHEfuAKgAAEDyDeW6GxWLRtGnTZDabdeaZZ2rixIlqamrS1KlTtXjxYi1evFiS9OMf/1gTJ06UJE2YMEGSlJCQoPnz52v79u39fj/P0xhZyGHgyGFwkMfARXoOT/Y8jZDeswsAAMJjMM/NmD17tmprayVJR48eVVNTk1JTU2UYhtrb2yVJH330kT7++GPNnDlTknTkyBFJktfr1c6dO5WRkRHCswIAYGAmr9frDXcQAABg+O3atUu/+MUvfM/NWLx4sd9zM7xer7Zt26aamhrFxcVp8eLFuuiii9TT06Pbb79dkjRmzBh961vf8r1e6K677tLRo0clSWeffbauu+46JSUlhesUAQDwodkNs7Vr16qsrCzcYUQ1chg4chgc5DFw5BCRgL+HgSOHgSOHwUEeAxfNOWQaMwAAAAAg5tDsAgAAAABiTvz3v//974c7iJFuypQp4Q4h6pHDwJHD4CCPgSOHiAT8PQwcOQwcOQwO8hi4aM0h9+wCAAAAAGIO05gBAAAAADHHHO4AYllNTY22bt0qwzBUWFioRYsW+W1vaWnRww8/rKNHjyo5OVk33XSTrFarJKm1tVWPPPKIXC6XJKmkpERnnnlmyM8h3ALJ4ZNPPqldu3bJ6/VqxowZuvbaa2UymcJxGmH10EMPadeuXUpJSdGmTZv6bPd6vdq6dav++te/KjExUTfccINvqsqOHTv07LPPSpIWL16sefPmhTL0iHG6Ofzwww+1ZcsWHT9+3Pcal4KCgjCcQfgF8vdQko4dO6ZbbrlFF1xwgYqLi0MZOmIMtTlw1ObAUZsDR20O3IiozV4Mi97eXu93vvMd76FDh7wnTpzw3nrrrd6///3vfmM2bdrk/dOf/uT1er3ev/3tb96f/OQnvm3r16/37t692+v1er3Hjx/3dnV1hSz2SBFIDt977z3vunXrvL29vd7e3l7vHXfc4X333XdDfQoRoba21vv+++97b7nlln63v/32297S0lKvYRjeffv2eUtKSrxer9fb3t7uvfHGG73t7e1+n0ei081hQ0ODt7Gx0ev1er0ul8v7rW99y9vR0RGyuCPJ6ebwU48//rj3wQcf9P785z8PRbiIUdTmwFGbg4PaHDhqc+BGQm1mGvMwqaurU1pamlJTU2U2m1VQUKCdO3f6jTl48KCys7MlSeeff77eeust3/re3l7l5ORIkpKSkpSYmBjaE4gAgeTQZDKpp6dHHo9HJ06cUG9vr1JSUkJ+DpFg+vTpSk5OHnD7W2+9pblz58pkMikrK0udnZ06cuSIampqlJOTo+TkZCUnJysnJ0c1NTUhjDxynG4O09PTNXHiREmSxWJRSkqKjh49GqqwI8rp5lCSPvjgA7W1tWnmzJmhChcxitocOGpzcFCbA0dtDtxIqM00u8PE7Xb7puxIktVqldvt9htz9tln680335Qkvfnmmzp+/Lja29vV2NiosWPHauPGjbrtttv0xBNPyDCMkMYfCQLJYVZWls4//3xdd911uu666zRz5kxNmjQppPFHC7fbLZvN5lv+NM//mn+LxdIn//jEQDn8rLq6Onk8HqWmpoY6vKgwUA4Nw9C2bdu0YsWKMEaHWEFtDhy1OTSozYGjNgcuFmozzW4YrVixQnv27NFtt92mPXv2yGKxKC4uToZhaO/evVqxYoV++MMf6vDhw9qxY0e4w41IA+Xw0KFDamho0COPPKJHH31U7777rvbu3RvucDFCHTlyRD/96U/17W9/W3Fx/G93KF544QXNmjXL7x93wHCiNgeO2oxoQG0+fdFUm3lA1TCxWCy+B1hIksvlksVi6TPm1ltvlSR1dXXpjTfe0NixY2WxWDR58mTfr0yzZ8/W/v37tWDBgtCdQAQIJIcvvfSSpk2bpqSkJEnSrFmztH//fp133nmhO4EoYbFY1Nra6lv+NM8Wi0V79uzxrXe73Zo+fXo4Qox4A+VQ+uThDWVlZfra176mrKyscIUY8QbK4f79+7V371698MIL6urqksfjUVJSkq6++uowRotoRW0OHLU5NKjNgaM2By4WajM/YwyTzMxMNTU1qbm5WR6PR06nU3a73W/M0aNHfVOgnnvuOc2fP1+SNHXqVB07dsx3/8C77747Iqf5BJJDm82mvXv3qre3Vx6PR3v27NHnP//5kJ9DNLDb7XrllVfk9Xq1f/9+jRkzRhMmTFBubq52796tjo4OdXR0aPfu3crNzQ13uBFpoBx6PB5t3LhRc+fOVX5+frjDjGgD5fDmm2/Www8/rM2bN2vFihWaO3duRBZTRAdqc+CozaFBbQ4ctTlwsVCbTV6v1xvuIGLVrl279Itf/EKGYWj+/PlavHixKisrlZmZKbvdrr/85S/61a9+JZPJpPPOO0/FxcVKSEiQJL3zzjvatm2bvF6vpkyZotWrV8tsHnkX4k83h4Zh6Oc//7lvelRubq6uueaaMJ9NeDz44IPas2eP2tvblZKSoqVLl8rj8UiSLrnkEnm9XpWXl2v37t0aNWqUbrjhBmVmZkqSXn75ZT333HOSPnm9waf/YBlpTjeHr7zyih5++GG/fxDfeOONmjx5cpjOJHwC+Xv4qR07duj999+P3NcbICpQmwNHbQ4ctTlw1ObAjYTaTLMLAAAAAIg5TGMGAAAAAMQcml0AAAAAQMyh2QUAAAAAxByaXQAAAABAzKHZBQAAAADEHJpdAEOydOlSHTp0KNxhAACA/0NtBvo38l4OB8SYG2+8Uf/4xz8UF/fP367mzZsXse87AwAg1lGbgchAswvEgNtvv105OTnhDgMAAPwfajMQfjS7QIzasWOHXnrpJU2ePFmvvPKKJkyYoOLiYs2YMUOS5Ha7tWXLFr333ntKTk7WV7/6VRUVFUmSDMPQb3/7W/3pT39SW1ubJk6cqO9973uy2WySpHfeeUf33nuvjh49qjlz5qi4uFgmkyls5woAQDSgNgOhRbMLxLADBw7owgsvVHl5ud58801t3LhRmzdvVnJysn784x8rIyNDjz76qBobG3XPPfcoLS1N2dnZ+v3vfy+Hw6GSkhJNnDhRH330kRITE33H3bVrl374wx/q+PHjuv3222W325WbmxvGMwUAIDpQm4HQodkFYsCGDRsUHx/vW16+fLnMZrNSUlJ02WWXyWQyqaCgQNu3b9euXbs0ffp0vffee1q7dq1GjRqlyZMnq7CwUH/+85+VnZ2tl156ScuXL1d6erokafLkyX7ft2jRIo0dO1Zjx47V+eefrw8//JCCCgDAZ1CbgfCj2QViwPe+970+9wXt2LFDFovFbwrT5z73Obndbh05ckTJyckaPXq0b5vNZtP7778vSXK5XEpNTR3w+8aPH+/7nJiYqK6urmCdCgAAMYHaDIQfrx4CYpjb7ZbX6/Utt7a2ymKxaMKECero6NDx48f7bJMkq9Wqw4cPhzxeAABiHbUZCB2aXSCGtbW1qaqqSh6PR6+//roaGho0a9Ys2Ww2nXPOOfrVr36lnp4effTRR/rTn/6kf/u3f5MkFRYWqrKyUk1NTfJ6vfroo4/U3t4e5rMBACD6UZuB0GEaMxAD7rvvPr93+eXk5OiCCy7QtGnT1NTUpOLiYo0fP1633HKLxo0bJ0las2aNtmzZotWrVys5OVlXXXWVb7rV5ZdfrhMnTugHP/iB2tvb9fnPf1633nprWM4NAIBoRG0Gws/k/ew8CgAx49PXG9xzzz3hDgUAAIjaDIQa05gBAAAAADGHZhcAAAAAEHOYxgwAAAAAiDlc2QUAAAAAxByaXQAAAABAzKHZBQAAAADEHJpdAAAAAEDModkFAAAAAMQcml0AAAAAQMyh2QUAAAAAxByaXQAAAABAzKHZBQAAAADEHJpdAAAAAEDMMYc7gFBobGwMdwgDstlsam1tDXcYUY0cBo4cBgd5DFyk5zA9PT3cIcQManNsI4eBI4fBQR4DF+k5PFlt5souAAAAACDm0OwCAAAAAGIOzS4AAAAAIOaMiHt2AQDB4fV61dXVJcMwZDKZgn78w4cPq7u7O+jHHQqv16u4uDglJSUNyzkCABBM1OaB0ewCAAatq6tLCQkJMpuHp3yYzWbFx8cPy7GHwuPxqKurS6NHjw53KAAAnBS1eWBMYwYADJphGMNWTCOJ2WyWYRjhDgMAgFOiNg+MZhcAMGgjaVrvSDpXAED0Gkn1aqjnSrMLAAAAAIg5NLsAgKjR1tamioqKIe+3YsUKtbW1BT8gAABGuEiuzTS7AICocfToUW3btq3Peo/Hc9L9nnjiCaWkpAxXWAAAjFiRXJtj/05mAEDMuPfee/XRRx/pS1/6khISEpSYmKiUlBTV1dXptdde06pVq9TY2Kju7m4VFxdr+fLlkqQLL7xQVVVV6uzs1PLlyzV79my99dZbSktL0+OPP85TlwEAOE2RXJtpdgEAp8X49RZ5/14f3IOenSktLR5w8x133KF9+/bpxRdflNPp1De+8Q29/PLLOuussyRJmzZt0oQJE3T8+HFddtll+spXviKLxeJ3jPr6em3evFkbNmzQ6tWr9cc//lFLliwJ7nkAABAG1GZ/NLsAgKiVm5vrK6aS9Pjjj6uqqkqS1NjYqPr6+j4FNSMjQ9nZ2ZKknJwc/f3vfw9dwAAAxLhIqs00uwCA0xL3/74V9GOazeZT3uPzWWPGjPF9djqdevXVV7V9+3aNHj1aV155pbq7u/vsk5iY6PscHx+vrq6uwIIGACBCUJv98YAqAEDUGDt2rDo6Ovrd1t7erpSUFI0ePVp1dXXatWtXiKMDAGDkieTazJVdAEDUsFgsuuCCC7RgwQIlJSXJZrP5ts2bN09PPPGELr74YmVmZiovLy+MkQIAMDJEcm02eb1eb0i/MQwaGxvDHcKAbDabWltbwx1GVCOHgSOHwTES8njs2DG/6UnBNtSpUsOpv3NNT08PUzSxh9oc28hh4MhhcIyEPFKbB67NTGMGAAAAAMQcml0AAAAAQMyh2QUAAAAAxByaXQAAAABAzKHZBQAAAADEHJpdAAAAAEDMCfl7dmtqarR161YZhqHCwkItWrTIb3tFRYVqa2slST09PWpra1NFRYVaWlq0ceNGGYah3t5eXXrppbrkkktCHT4AIIpMmzZNBw4cCHcYEe9UtXnHjh164oknZLFYJEmXXnqpCgsLJUmtra165JFH5HK5JEklJSU688wzQ3sCAICoEcraHNJm1zAMlZeXa926dbJarSopKZHdbtekSZN8Y1auXOn7XFVVpfr6eknShAkT9IMf/EAJCQnq6urSd7/7Xdntdl/hBQAAQzeY2ixJBQUFKi4u7rP/z372My1evFg5OTnq6uqSyWQKVegAAJxUSJvduro6paWlKTU1VdInhXPnzp19CuqnHA6Hli5dKumTlxl/6sSJEzIMY/gDBgBElHvvvVfp6em+H0Y3bdqk+Ph4OZ1OtbW1yePx6LbbbtOXv/zl8AYaRYZamz/r4MGD6u3tVU5OjiQpKSlpWGMFAESeSK7NIW123W63rFarb9lqtQ54CbulpUXNzc3Kzs72rWttbVVZWZkOHTqk5cuXc1UXAMLo528dVv2RrqAeM9M6RqvyPjfg9oULF2r9+vW+grp9+3b98pe/VHFxscaNGye3260rrrhCl1xyCVcYB2mwtfmNN97Q3r17NXHiRF1zzTWy2WxqbGzU2LFjtXHjRjU3N2vGjBm6+uqrFRfHI0EAIByozf5Cfs/uYDkcDuXn5/sVTJvNpo0bN8rtdmvDhg3Kz8/X+PHj++xbXV2t6upqSVJZWZlsNlvI4h4qs9kc0fFFA3IYOHIYHCMhj4cPH/bNtImLixuWovXZmTz/Kjc3Vy6XS62trXK5XBo/frzS09N155136vXXX1dcXJwOHTqkI0eO+O4bPdnxTiYxMTHm/zwH64tf/KIuuugiJSQk6MUXX9TmzZu1fv16GYahvXv36v7775fNZtMDDzygHTt2aMGCBX2OQW0eWchh4MhhcIyEPFKbTxL3aX3LabJYLL4HWEiSy+Ua8Oqs0+ns996gT4+TkZGh9957T/n5+X22FxUVqaioyLfc2toaYOTDx2azRXR80YAcBo4cBsdIyGN3d7fi4+Ml6aS/8p4us9ksj8dz0jGXXXaZnn/+eTU3N+uKK67Qb37zG7W0tKiqqkoJCQm68MIL1dnZ6TvOqY43kO7u7j5/nunp6ad1rEg2mNo8btw43+fCwkI9+eSTvn0nT57smwI9e/Zs7d+/v99ml9o8spDDwJHD4BgJeaQ2D1ybQzrPKDMzU01NTWpubpbH45HT6ZTdbu8zrqGhQZ2dncrKyvKtc7lc6unpkSR1dHRo3759MfmPDgDAyS1cuFDPP/+8/vCHP+jyyy9Xe3u7bDabEhIS5HA4dPDgwXCHGFUGU5uPHDni+/zWW2/57uedOnWqjh07pqNHj0qS3n333UHd6wsAiC2RWptDemU3Pj5eq1atUmlpqQzD+P/t3X90VPWd//FXMhNAmCwyMzU/TJBlFBUwxDBaOrhZwuS0nN3+yIkuHFM4ccmxUrD2rKuVtNHsarOmK55t14PWpTEssD0nZ6v1nN09OUfCmno22WKyNOkCQQiC1RAMmYmEAAEmd75/sMzXaQgNzGR+3Hk+/pr7a+Z934fjx1fu596rkpIS5efnq6mpSS6XKzS4trW1yePxhF2C7+vr044dO5SWlqZgMKivfe1rmjt3bizLBwAkgDvvvFNnz54NPVSpvLxclZWV8nq9Kigo0O233x7vEpPKZMbm5uZmdXZ2ymKxyGazaePGjZIuT5dbt26dnn/+eQWDQc2fPz/s6i0AIDUk6ticFgwGg3H55Rg6ceJEvEuYUCpMrZhq9DBy9DA6UqGP586d08yZM6fs+yczVSpWrnauzCiKHsZmc6OHkaOH0ZEKfWRsTpBpzAAAAAAAxAJhFwAAAABgOoRdAMCkpcCdLyGpdK4AgOSVSuPV9Z4rYRcAMGnp6ekJc9/OVAoEAmHveQcAIFExNk8spk9jBgAktxkzZmh0dFQXLlyYkpfWT58+XRcuXIj6916PYDCo9PR0zZgxI651AAAwGYzNEyPsw5a2kQAAIABJREFUAgAmLS0tTTfddNOUfX8qPDUTAIBoYmyeGHO0AAAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmY413AQAAIL66urrU2NgowzDk9XpVVlYWtr21tVU7d+6U3W6XJK1atUper1eStGbNGs2dO1eS5HQ69cwzz8S2eAAAJkDYBQAghRmGoYaGBtXU1MjhcKi6ulput1t5eXlh+3k8HlVVVY07ftq0aXrppZdiVS4AAJPGNGYAAFJYb2+vsrOzlZWVJavVKo/Ho46OjniXBQBAxLiyCwBACvP7/XI4HKFlh8OhI0eOjNtv79696unpUU5OjiorK+V0OiVJly5d0ubNm2WxWPSNb3xD999//1V/p6WlRS0tLZKk+vr60PGJyGq1JnR9yYAeRo4eRgd9jFwy95CwCwAArmnp0qVavny5MjIytHv3bm3dulW1tbWSpFdffVV2u12ffvqpnn/+ec2dO1fZ2dnjvqO0tFSlpaWh5cHBwZjVf72cTmdC15cM6GHk6GF00MfIJXoPc3NzJ9zGNGYAAFKY3W6Xz+cLLft8vtCDqK7IzMxURkaGJMnr9erDDz8MO16SsrKytHDhQh0/fnzqiwYAYBIIuwAApDCXy6X+/n4NDAwoEAiovb1dbrc7bJ+hoaHQ587OztDDq0ZGRnTp0iVJ0vDwsD744INxD7YCACBemMYMAEAKs1gsWr9+verq6mQYhkpKSpSfn6+mpia5XC653W41Nzers7NTFotFNptNGzdulCT19fXpn/7pn5Seni7DMFRWVkbYBQAkjLRgMBiMdxFT7cSJE/EuYUKJPgc+GdDDyNHD6KCPkUv0Hl7rviBcH8Zmc6OHkaOH0UEfI5foPeSeXQAAAABASiHsAgAAAABMh7ALAAAAADAdwi4AAAAAwHQIuwAAAAAA04n5q4e6urrU2NgowzDk9XpVVlYWtn379u06cOCAJOnixYs6ffq0tm/fruPHj2vbtm06f/680tPTVV5eLo/HE+vyAQAAAABJIKZh1zAMNTQ0qKamRg6HQ9XV1XK73WHv5HvkkUdCn5ubm3Xs2DFJ0rRp0/T4448rJydHfr9fmzdv1pIlSzRr1qxYngIAAAAAIAnEdBpzb2+vsrOzlZWVJavVKo/Ho46Ojgn3b2tr0wMPPCDp8vuTcnJyJEl2u12zZ8/W8PBwTOoGAAAAACSXmIZdv98vh8MRWnY4HPL7/Vfd99SpUxoYGNDixYvHbevt7VUgEFBWVtaU1QoAAAAASF4xv2d3stra2rRs2TKlp4fn8aGhIb3yyivatGnTuG1XtLS0qKWlRZJUX18vp9M55fXeKKvVmtD1JQN6GDl6GB30MXL0EAAAREtMw67dbpfP5wst+3w+2e32q+7b3t6uqqqqsHXnzp1TfX29Hn74YS1YsGDC3yktLVVpaWloeXBwMMLKp47T6Uzo+pIBPYwcPYwO+hi5RO9hbm5uvEsAAACTFNNpzC6XS/39/RoYGFAgEFB7e7vcbve4/fr6+nT27NmwQBsIBLRlyxYVFxdr2bJlsSwbAAAAAJBkYnpl12KxaP369aqrq5NhGCopKVF+fr6amprkcrlCwbetrU0ej0dpaWmhY9vb29XT06MzZ86otbVVkrRp0ybNmzcvlqcAAAAAAEgCMb9nt6ioSEVFRWHr1qxZE7a8evXqcccVFxeruLh4SmsDAAAAAJhDTKcxAwAAAAAQC4RdAAAAAIDpEHYBAAAAAKZD2AUAAAAAmA5hFwAAAABgOoRdAAAAAIDpEHYBAAAAAKZD2AUAAAAAmI413gUAAID46urqUmNjowzDkNfrVVlZWdj21tZW7dy5U3a7XZK0atUqeb3e0PZz587pySef1H333aeqqqqY1g4AwEQIuwAApDDDMNTQ0KCamho5HA5VV1fL7XYrLy8vbD+PxzNhkG1qatLdd98di3IBAJg0pjEDAJDCent7lZ2draysLFmtVnk8HnV0dEz6+A8//FCnT5/WkiVLprBKAACuH2EXAIAU5vf75XA4QssOh0N+v3/cfnv37tVTTz2ll19+WYODg5IuXxXesWOH1q1bF7N6AQCYLKYxAwCAa1q6dKmWL1+ujIwM7d69W1u3blVtba3eeecd3XvvvWFheSItLS1qaWmRJNXX18vpdE512TfMarUmdH3JgB5Gjh5GB32MXDL3kLALAEAKs9vt8vl8oWWfzxd6ENUVmZmZoc9er1e7du2SJB0+fFg9PT165513NDo6qkAgoBkzZuib3/zmuN8pLS1VaWlpaPnK1eFE5HQ6E7q+ZEAPI0cPo4M+Ri7Re5ibmzvhNsIuAAApzOVyqb+/XwMDA7Lb7Wpvb9cTTzwRts/Q0JDmzJkjSers7Aw9vOrz+7W2turo0aNXDboAAMQDYRcAgBRmsVi0fv161dXVyTAMlZSUKD8/X01NTXK5XHK73WpublZnZ6csFotsNps2btwY77IBAPiDCLsAAKS4oqIiFRUVha1bs2ZN6HNFRYUqKiqu+R0rVqzQihUrpqI8AABuCE9jBgAAAACYDmEXAAAAAGA6hF0AAAAAgOkQdgEAAAAApkPYBQAAAACYDk9jBgAgye3fv1+33HKLbrnlFg0NDelf/uVflJ6eroqKCt18883xLg8AgLjgyi4AAEmuoaFB6emXh/QdO3ZobGxMaWlpev311+NcGQAA8cOVXQAAkpzf75fT6dTY2Ji6u7v16quvymq16rHHHot3aQAAxA1hFwCAJHfTTTfps88+08cff6y8vDzNmDFDgUBAgUAg3qUBABA3hF0AAJLcqlWrVF1drUAgoEceeUSSdOjQId16663xLQwAgDgi7AIAkOTKysp0//33Kz09XdnZ2ZIku92uDRs2xLkyAADiJyoPqPrVr34Vja8BAAA3KDc3NxR09+/fr88++0xz586Nc1UAAMTPdV3Z/eSTT8atCwaDamlp0Z/+6Z9GrSgAADB5tbW1evjhh3XXXXfp7bff1n/8x38oPT1dX/nKV1ReXh7v8gAAiIvrCrs/+MEP9MUvfnHc+lOnTkWtIAAAcH0+/vhjLViwQJK0Z88e1dbWasaMGXr22WcJuwCAlHVdYffWW2/VunXrlJmZGbb+xRdfjGpRAABg8oLBoCTp5MmTkqS8vDxJ0tmzZ+NWEwAA8XbNe3a//e1vhy0/++yzmjVr1rj9qquro1sVAACYtDvvvFNvvPGGdu7cqfvuu0/S5eD7+3+cBgAglVwz7P7+X4Sfe+45padH5ZlWAAAgSjZt2qSZM2fqtttu0+rVqyVJJ06c0J/92Z/FuTIAAOLnmtOY09LSwpYHBwentBgAAHD9MjMzVVFREbauqKgoTtUAAJAYeM8uAABJLhAI6K233tJ7772noaEhzZkzR8XFxSovL5fVylAPAEhN1xwBR0dHVVVVpby8POXl5SkQCOjYsWOaO3euLBbLDf1gV1eXGhsbZRiGvF6vysrKwrZv375dBw4ckCRdvHhRp0+f1vbt2yVJdXV1OnLkiO666y5t3rz5hn4fAACz2bVrl44ePapHH31UX/jCF3Tq1Cm9+eabOnfunB555JF4lwcAQFxcM+y+8cYbOn78uI4fP65jx44pOztb3//+95Wenq65c+dq/vz5evTRRyf9Y4ZhqKGhQTU1NXI4HKqurpbb7Q49NVJS2KDc3NysY8eOhZa//vWv68KFC2ppabmOUwQAwNx+/etf66WXXgo9kCo3N1d//Md/rKeffpqwCwBIWdcMu7NmzdKiRYu0aNGi0LpAIKDf/e53oRB8PXp7e5Wdna2srCxJksfjUUdHR1jY/by2trbQgzYk6Z577gld9QUAAJddefUQAAD4/677Rh6r1ar58+dr/vz51/1jfr9fDocjtOxwOHTkyJGr7nvq1CkNDAxo8eLF1/07AACkki996Uv60Y9+pIceekhOp1ODg4N688039aUvfWlSx/+hW4xaW1u1c+dO2e12SdKqVavk9Xp16tQpbdmyRYZhaGxsTKtWrdKXv/zlqJ8fAAA3ImGfWtHW1qZly5bd0KuOWlpaQlOd6+vr5XQ6o11e1Fit1oSuLxnQw8jRw+igj5Gjhzdm7dq1evPNN9XQ0KChoSHZ7XZ5PB4FAoE/eOxkbjGSLs/GqqqqCls3Z84c/fCHP1RGRoZGR0f113/913K73aFQDABAPMU07Nrtdvl8vtCyz+ebcEBsb28fN6hOVmlpqUpLS0PLifzKpCt/gceNo4eRo4fRQR8jl+g9zM3NjXcJV2W1WrVmzRqtWbMmtO7ixYtat26d1q5de81jr/cWo9//3SsuXbokwzBu8AwAAIi+mIZdl8ul/v5+DQwMyG63q729XU888cS4/fr6+nT27FktWLAgluUBAGAaaWlpk9pvsrcY7d27Vz09PcrJyVFlZWXoCvzg4KDq6+t18uRJrV27lqu6AICEEdOwa7FYtH79etXV1ckwDJWUlCg/P19NTU1yuVxyu92SLk9h9ng84wbq5557Tn19fRodHdWGDRu0YcMGFRYWxvIUAABIOUuXLtXy5cuVkZGh3bt3a+vWraqtrZV0+Wr8li1b5Pf79dJLL2nZsmW6+eabx30HtxilFnoYOXoYHfQxcsncw5jfs1tUVKSioqKwdZ+fdiUp7AnMn/f8889PWV0AACSb/fv3T7htMvfrSpO7xejKK40kyev1ateuXVf9nvz8fB06dEjLli0bt51bjFILPYwcPYwO+hi5RO/htW4xStgHVAEAgGt77bXXrrl9Mn+Jn8wtRkNDQ5ozZ44kqbOzM3Q/r8/nU2ZmpqZNm6aRkRF98MEH+upXv3qDZwMAQHQRdgEASFJbt26N+Dsmc4tRc3OzOjs7ZbFYZLPZtHHjRkmXn7GxY8cOpaWlKRgM6mtf+5rmzp0bcU0AAERDWjAF3kR/4sSJeJcwoUSfFpAM6GHk6GF00MfIJXoPE/VpzMmIsdnc6GHk6GF00MfIJXoPrzU2X/9LbAEAAAAASHCEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQAAAACA6VjjXQAAAIivrq4uNTY2yjAMeb1elZWVhW1vbW3Vzp07ZbfbJUmrVq2S1+vV8ePHtW3bNp0/f17p6ekqLy+Xx+OJxykAADAOYRcAgBRmGIYaGhpUU1Mjh8Oh6upqud1u5eXlhe3n8XhUVVUVtm7atGl6/PHHlZOTI7/fr82bN2vJkiWaNWtWLE8BAICrYhozAAAprLe3V9nZ2crKypLVapXH41FHR8ekjs3NzVVOTo4kyW63a/bs2RoeHp7KcgEAmDSu7AIAkML8fr8cDkdo2eFw6MiRI+P227t3r3p6epSTk6PKyko5nc6w7b29vQoEAsrKyprymgEAmAzCLgAAuKalS5dq+fLlysjI0O7du7V161bV1taGtg8NDemVV17Rpk2blJ5+9UljLS0tamlpkSTV19ePC8uJxGq1JnR9yYAeRo4eRgd9jFwy95CwCwBACrPb7fL5fKFln88XehDVFZmZmaHPXq9Xu3btCi2fO3dO9fX1evjhh7VgwYIJf6e0tFSlpaWh5cHBwWiUPyWcTmdC15cM6GHk6GF00MfIJXoPc3NzJ9zGPbsAAKQwl8ul/v5+DQwMKBAIqL29XW63O2yfoaGh0OfOzs7Qw6sCgYC2bNmi4uJiLVu2LKZ1AwDwh3BlFwCAFGaxWLR+/XrV1dXJMAyVlJQoPz9fTU1Ncrlccrvdam5uVmdnpywWi2w2mzZu3ChJam9vV09Pj86cOaPW1lZJ0qZNmzRv3rz4nRAAAP+HsAsAQIorKipSUVFR2Lo1a9aEPldUVKiiomLcccXFxSouLp7y+gAAuBFMYwYAAAAAmA5hFwAAAABgOoRdAAAAAIDpxPye3a6uLjU2NsowDHm9XpWVlYVt3759uw4cOCBJunjxok6fPq3t27dLklpbW/XWW29JksrLy7VixYpYlg4AAAAASBIxDbuGYaihoUE1NTVyOByqrq6W2+0OvcJAkh555JHQ5+bmZh07dkySNDIyol/84heqr6+XJG3evFlut1s2my2WpwAAAAAASAIxncbc29ur7OxsZWVlyWq1yuPxqKOjY8L929ra9MADD0i6fEW4oKBANptNNptNBQUF6urqilXpAAAAAIAkEtOw6/f75XA4QssOh0N+v/+q+546dUoDAwNavHjxVY+12+0THgsAAAAASG0J+57dtrY2LVu2TOnp15/HW1pa1NLSIkmqr6+X0+mMdnlRY7VaE7q+ZEAPI0cPo4M+Ro4eAgCAaIlp2LXb7fL5fKFln88nu91+1X3b29tVVVUVduzBgwdDy36/XwsXLrzqsaWlpSotLQ0tDw4ORlr6lHE6nQldXzKgh5Gjh9FBHyOX6D3Mzc2NdwkAAGCSYjqN2eVyqb+/XwMDAwoEAmpvb5fb7R63X19fn86ePasFCxaE1hUWFqq7u1sjIyMaGRlRd3e3CgsLY1k+AAAAACBJxPTKrsVi0fr161VXVyfDMFRSUqL8/Hw1NTXJ5XKFgm9bW5s8Ho/S0tJCx9psNj344IOqrq6WJD300EM8iRkAAAAAcFUxv2e3qKhIRUVFYevWrFkTtrx69eqrHrty5UqtXLlyymoDAAAAAJhDTKcxAwAAAAAQC4RdAAAAAIDpEHYBAAAAAKZD2AUAAAAAmA5hFwAAAABgOoRdAAAAAIDpEHYBAAAAAKZD2AUAAAAAmA5hFwAAAABgOoRdAAAAAIDpEHYBAAAAAKZjjXcBAAAgvrq6utTY2CjDMOT1elVWVha2vbW1VTt37pTdbpckrVq1Sl6vV5JUV1enI0eO6K677tLmzZtjXjsAABMh7AIAkMIMw1BDQ4NqamrkcDhUXV0tt9utvLy8sP08Ho+qqqrGHf/1r39dFy5cUEtLS6xKBgBgUpjGDABACuvt7VV2draysrJktVrl8XjU0dEx6ePvuece3XTTTVNYIQAAN4YruwAApDC/3y+HwxFadjgcOnLkyLj99u7dq56eHuXk5KiyslJOp/O6fqelpSV09be+vv66j48lq9Wa0PUlA3oYOXoYHfQxcsncQ8IuAAC4pqVLl2r58uXKyMjQ7t27tXXrVtXW1l7Xd5SWlqq0tDS0PDg4GO0yo8bpdCZ0fcmAHkaOHkYHfYxcovcwNzd3wm1MYwYAIIXZ7Xb5fL7Qss/nCz2I6orMzExlZGRIkrxerz788MOY1ggAwI0g7AIAkMJcLpf6+/s1MDCgQCCg9vZ2ud3usH2GhoZCnzs7O8c9vAoAgETENGYAAFKYxWLR+vXrVVdXJ8MwVFJSovz8fDU1Ncnlcsntdqu5uVmdnZ2yWCyy2WzauHFj6PjnnntOfX19Gh0d1YYNG7RhwwYVFhbG8YwAALiMsAsAQIorKipSUVFR2Lo1a9aEPldUVKiiouKqxz7//PNTWhsAADeKacwAAAAAANMh7AIAAAAATIewCwAAAAAwHcIuAAAAAMB0CLsAAAAAANMh7AIAAAAATIewCwAAAAAwHcIuAAAAAMB0CLsAAAAAANMh7AIAAAAATIewCwAAAAAwHcIuAAAAAMB0CLsAAAAAANMh7AIAAAAATIewCwAAAAAwHcIuAAAAAMB0rLH+wa6uLjU2NsowDHm9XpWVlY3bp729Xf/6r/+qtLQ03Xbbbfrud78rSdq1a5d+85vfSJIefPBBeTyemNYOAAAAAEgOMQ27hmGooaFBNTU1cjgcqq6ultvtVl5eXmif/v5+vf3223rhhRdks9l0+vRpSdK+fft07Ngx/f3f/70uXbqkv/3bv1VhYaFmzpwZy1MAAAAAACSBmE5j7u3tVXZ2trKysmS1WuXxeNTR0RG2z549e/SVr3xFNptNkjR79mxJ0ieffKK7775bFotFM2bM0Ny5c9XV1RXL8gEAAAAASSKmYdfv98vhcISWHQ6H/H5/2D4nTpxQf3+/nn32Wf3gBz8IBdrbbrtN3d3dunDhgoaHh3XgwAH5fL5Ylg8AAAAASBIxv2f3DzEMQ/39/aqtrZXf71dtba22bNmiJUuW6OjRo6qpqdEf/dEfacGCBUpPv3pWb2lpUUtLiySpvr5eTqczlqdwXaxWa0LXlwzoYeToYXTQx8jRQwAAEC0xDbt2uz3saqzP55Pdbh+3zx133CGr1apbbrlFOTk56u/v1+23367y8nKVl5dLkn7yk58oJyfnqr9TWlqq0tLS0PLg4OAUnE10OJ3OhK4vGdDDyNHD6KCPkUv0Hubm5sa7BAAAMEkxDbsul0v9/f0aGBiQ3W5Xe3u7nnjiibB97r//fv3Xf/2XSkpKNDw8rP7+fmVlZckwDJ09e1aZmZn66KOP9Lvf/U5LliyJZfkAAJjSH3pTQmtrq3bu3Bn6A/WqVavk9XpD29566y1JUnl5uVasWBHT2gEAmEhMw67FYtH69etVV1cnwzBUUlKi/Px8NTU1yeVyye12a8mSJeru7tZf/dVfKT09XWvXrlVmZqYuXryo5557TpI0c+ZMfec735HFYoll+QAAmM5k3pQgSR6PR1VVVWHrRkZG9Itf/EL19fWSpM2bN8vtdoceMgkAQDzF/J7doqIiFRUVha1bs2ZN6HNaWpoqKytVWVkZts+0adP0D//wDzGpEQCAVPH5NyVICr0p4ffD7tV0dXWpoKAgFG4LCgrU1dWlBx54YEprBgBgMhLuAVUAACB2rvamhCNHjozbb+/everp6VFOTo4qKyvldDrHHWu328e9ZQEAgHgh7AIAgGtaunSpli9froyMDO3evVtbt25VbW3tdX0Hb0pILfQwcvQwOuhj5JK5h4RdAABS2GTelJCZmRn67PV6tWvXrtCxBw8eDG3z+/1auHDhVX+HNyWkFnoYOXoYHfQxconew2u9KeHqL6oFAAAp4fNvSggEAmpvb5fb7Q7bZ2hoKPS5s7MzdD9vYWGhuru7NTIyopGREXV3d6uwsDCm9QMAMBGu7AIAkMIm86aE5uZmdXZ2ymKxyGazaePGjZIkm82mBx98UNXV1ZKkhx56iCcxAwASBmEXAIAU94felFBRUaGKioqrHrty5UqtXLlySusDAOBGMI0ZAAAAAGA6acFgMBjvIgAAAAAAiCau7MbZ5s2b411C0qOHkaOH0UEfI0cPkQj4dxg5ehg5ehgd9DFyydxDwi4AAAAAwHQIuwAAAAAA07H8zd/8zd/Eu4hUN3/+/HiXkPToYeToYXTQx8jRQyQC/h1Gjh5Gjh5GB32MXLL2kAdUAQAAAABMh2nMAAAAAADTsca7ADPr6upSY2OjDMOQ1+tVWVlZ2PZTp07ptdde0/DwsGw2m77zne/I4XBIkgYHB/XTn/5UPp9PklRdXa1bbrkl5ucQb5H0cNeuXdq3b5+CwaDuuece/eVf/qXS0tLicRpx9eqrr2rfvn2aPXu2Xn755XHbg8GgGhsb9Zvf/EbTp0/Xxo0bQ1NVWltb9dZbb0mSysvLtWLFiliWnjButIfHjx/Xtm3bdP78eaWnp6u8vFwejycOZxB/kfw7lKRz587pySef1H333aeqqqpYlg6TYWyOHGNz5BibI8fYHLmUGJuDmBJjY2PBxx9/PHjy5MngpUuXgk899VTw448/Dtvn5ZdfDr777rvBYDAY/N///d/gP/7jP4a21dbWBru7u4PBYDB4/vz54OjoaMxqTxSR9PDQoUPBmpqa4NjYWHBsbCz4/e9/P7h///5Yn0JCOHDgQPDo0aPBJ5988qrb/+d//idYV1cXNAwj+MEHHwSrq6uDwWAweObMmeCmTZuCZ86cCfucim60h319fcETJ04Eg8Fg0OfzBR999NHgyMhIzOpOJDfawyveeOON4I9//OPgz372s1iUC5NibI4cY3N0MDZHjrE5cqkwNjONeYr09vYqOztbWVlZslqt8ng86ujoCNvnk08+0eLFiyVJixYtUmdnZ2j92NiYCgoKJEkzZszQ9OnTY3sCCSCSHqalpenixYsKBAK6dOmSxsbGNHv27JifQyJYuHChbDbbhNs7OztVXFystLQ0LViwQGfPntXQ0JC6urpUUFAgm80mm82mgoICdXV1xbDyxHGjPczNzVVOTo4kyW63a/bs2RoeHo5V2QnlRnsoSR9++KFOnz6tJUuWxKpcmBRjc+QYm6ODsTlyjM2RS4WxmbA7Rfx+f2jKjiQ5HA75/f6wfW677Ta9//77kqT3339f58+f15kzZ3TixAnNmjVLW7Zs0fe+9z3t3LlThmHEtP5EEEkPFyxYoEWLFulb3/qWvvWtb2nJkiXKy8uLaf3Jwu/3y+l0hpav9Pn3+2+328f1H5dN1MPP6+3tVSAQUFZWVqzLSwoT9dAwDO3YsUPr1q2LY3UwC8bmyDE2xwZjc+QYmyNnhrGZsBtH69at08GDB/W9731PBw8elN1uV3p6ugzDUE9Pj9atW6cXX3xRn376qVpbW+NdbkKaqIcnT55UX1+ffvrTn+r111/X/v371dPTE+9ykaKGhob0yiuv6Nvf/rbS0/nP7vV45513dO+994b9zx0wlRibI8fYjGTA2Hzjkmls5gFVU8Rut4ceYCFJPp9Pdrt93D5PPfWUJGl0dFR79+7VrFmzZLfbNW+D19oUAAAF1klEQVTevNBfme6//34dPnxYK1eujN0JJIBIerhnzx7dcccdmjFjhiTp3nvv1eHDh3X33XfH7gSShN1u1+DgYGj5Sp/tdrsOHjwYWu/3+7Vw4cJ4lJjwJuqhdPnhDfX19Xr44Ye1YMGCeJWY8Cbq4eHDh9XT06N33nlHo6OjCgQCmjFjhr75zW/GsVokK8bmyDE2xwZjc+QYmyNnhrGZP2NMEZfLpf7+fg0MDCgQCKi9vV1utztsn+Hh4dAUqF/+8pcqKSmRJN1+++06d+5c6P6B/fv3p+Q0n0h66HQ61dPTo7GxMQUCAR08eFC33nprzM8hGbjdbr333nsKBoM6fPiwZs6cqTlz5qiwsFDd3d0aGRnRyMiIuru7VVhYGO9yE9JEPQwEAtqyZYuKi4u1bNmyeJeZ0Cbq4RNPPKHXXntNW7du1bp161RcXJyQgymSA2Nz5BibY4OxOXKMzZEzw9icFgwGg/Euwqz27dunf/7nf5ZhGCopKVF5ebmamprkcrnkdrv161//Wj//+c+Vlpamu+++W1VVVcrIyJAk/fa3v9WOHTsUDAY1f/58PfbYY7JaU+9C/I320DAM/exnPwtNjyosLFRlZWWczyY+fvzjH+vgwYM6c+aMZs+erdWrVysQCEiSvvzlLysYDKqhoUHd3d2aNm2aNm7cKJfLJUn6z//8T/3yl7+UdPn1Blf+hyXV3GgP33vvPb322mth/0O8adMmzZs3L05nEj+R/Du8orW1VUePHk3c1xsgKTA2R46xOXKMzZFjbI5cKozNhF0AAAAAgOkwjRkAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDqEXQDXZfXq1Tp58mS8ywAAAP+HsRm4utR7ORxgMps2bdJnn32m9PT//7erFStWJOz7zgAAMDvGZiAxEHYBE3jmmWdUUFAQ7zIAAMD/YWwG4o+wC5hUa2ur9uzZo3nz5um9997TnDlzVFVVpXvuuUeS5Pf7tW3bNh06dEg2m03f+MY3VFpaKkkyDENvv/223n33XZ0+fVo5OTl6+umn5XQ6JUm//e1v9Xd/93caHh7WAw88oKqqKqWlpcXtXAEASAaMzUBsEXYBEzty5Ii++MUvqqGhQe+//762bNmirVu3ymaz6Sc/+Yny8/P1+uuv68SJE3rhhReUnZ2txYsX69///d/V1tam6upq5eTk6KOPPtL06dND37tv3z69+OKLOn/+vJ555hm53W4VFhbG8UwBAEgOjM1A7BB2ARN46aWXZLFYQstr166V1WrV7Nmz9ed//udKS0uTx+PRv/3bv2nfvn1auHChDh06pM2bN2vatGmaN2+evF6vfvWrX2nx4sXas2eP1q5dq9zcXEnSvHnzwn6vrKxMs2bN0qxZs7Ro0SIdP36cARUAgM9hbAbij7ALmMDTTz897r6g1tZW2e32sClMX/jCF+T3+zU0NCSbzaabbroptM3pdOro0aOSJJ/Pp6ysrAl/7+abbw59nj59ukZHR6N1KgAAmAJjMxB/vHoIMDG/369gMBhaHhwclN1u15w5czQyMqLz58+P2yZJDodDn376aczrBQDA7Bibgdgh7AImdvr0aTU3NysQCOi///u/1dfXp3vvvVdOp1N33nmnfv7zn+vixYv66KOP9O677+pP/uRPJEler1dNTU3q7+9XMBjURx99pDNnzsT5bAAASH6MzUDsMI0ZMIEf/ehHYe/yKygo0H333ac77rhD/f39qqqq0s0336wnn3xSmZmZkqTvfve72rZtmx577DHZbDb9xV/8RWi61Ve/+lVdunRJP/zhD3XmzBndeuuteuqpp+JybgAAJCPGZiD+0oKfn0cBwDSuvN7ghRdeiHcpAABAjM1ArDGNGQAAAABgOoRdAAAAAIDpMI0ZAAAAAGA6XNkFAAAAAJgOYRcAAAAAYDqEXQAAAACA6RB2AQAAAACmQ9gFAAAAAJgOYRcAAAAAYDr/D4Muiw7GTO3bAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x648 with 4 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyRiDTC7U3ct"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/models/cnn/cnn-frozen-embeddings-09-0.77.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUWV7bdBU3ct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6276d70-ef9b-4101-e88e-b007a47623e3"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted = np.round(model.predict(x_test_seq))\n",
        "print(classification_report(y_test, predicted, digits=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.77503   0.77272   0.77388     22457\n",
            "           1    0.77194   0.77426   0.77310     22313\n",
            "\n",
            "    accuracy                        0.77349     44770\n",
            "   macro avg    0.77349   0.77349   0.77349     44770\n",
            "weighted avg    0.77349   0.77349   0.77349     44770\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boJJvqZgU3cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23cfdf78-64fc-49b1-a337-69ff2990213b"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.layers[1].trainable = True\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision, recall, f1])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 26)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 26, 200)      20000000    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 26, 200)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_80 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_81 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_82 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_83 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_84 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_85 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_86 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_87 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_88 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_89 (Conv1D)              (None, 25, 1)        401         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_90 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_91 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_92 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_93 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_94 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_95 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_96 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_97 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_98 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_99 (Conv1D)              (None, 24, 1)        601         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_100 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_101 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_102 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_103 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_104 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_105 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_106 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_107 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_108 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_109 (Conv1D)             (None, 23, 1)        801         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_110 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_111 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_112 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_113 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_114 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_115 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_116 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_117 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_118 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_119 (Conv1D)             (None, 22, 1)        1001        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_80 (Global (None, 1)            0           conv1d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_81 (Global (None, 1)            0           conv1d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_82 (Global (None, 1)            0           conv1d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_83 (Global (None, 1)            0           conv1d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_84 (Global (None, 1)            0           conv1d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_85 (Global (None, 1)            0           conv1d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_86 (Global (None, 1)            0           conv1d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_87 (Global (None, 1)            0           conv1d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_88 (Global (None, 1)            0           conv1d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_89 (Global (None, 1)            0           conv1d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_90 (Global (None, 1)            0           conv1d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_91 (Global (None, 1)            0           conv1d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_92 (Global (None, 1)            0           conv1d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_93 (Global (None, 1)            0           conv1d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_94 (Global (None, 1)            0           conv1d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_95 (Global (None, 1)            0           conv1d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_96 (Global (None, 1)            0           conv1d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_97 (Global (None, 1)            0           conv1d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_98 (Global (None, 1)            0           conv1d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_99 (Global (None, 1)            0           conv1d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_100 (Globa (None, 1)            0           conv1d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_101 (Globa (None, 1)            0           conv1d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_102 (Globa (None, 1)            0           conv1d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_103 (Globa (None, 1)            0           conv1d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_104 (Globa (None, 1)            0           conv1d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_105 (Globa (None, 1)            0           conv1d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_106 (Globa (None, 1)            0           conv1d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_107 (Globa (None, 1)            0           conv1d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_108 (Globa (None, 1)            0           conv1d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_109 (Globa (None, 1)            0           conv1d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_110 (Globa (None, 1)            0           conv1d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_111 (Globa (None, 1)            0           conv1d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_112 (Globa (None, 1)            0           conv1d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_113 (Globa (None, 1)            0           conv1d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_114 (Globa (None, 1)            0           conv1d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_115 (Globa (None, 1)            0           conv1d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_116 (Globa (None, 1)            0           conv1d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_117 (Globa (None, 1)            0           conv1d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_118 (Globa (None, 1)            0           conv1d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_119 (Globa (None, 1)            0           conv1d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 40)           0           global_max_pooling1d_80[0][0]    \n",
            "                                                                 global_max_pooling1d_81[0][0]    \n",
            "                                                                 global_max_pooling1d_82[0][0]    \n",
            "                                                                 global_max_pooling1d_83[0][0]    \n",
            "                                                                 global_max_pooling1d_84[0][0]    \n",
            "                                                                 global_max_pooling1d_85[0][0]    \n",
            "                                                                 global_max_pooling1d_86[0][0]    \n",
            "                                                                 global_max_pooling1d_87[0][0]    \n",
            "                                                                 global_max_pooling1d_88[0][0]    \n",
            "                                                                 global_max_pooling1d_89[0][0]    \n",
            "                                                                 global_max_pooling1d_90[0][0]    \n",
            "                                                                 global_max_pooling1d_91[0][0]    \n",
            "                                                                 global_max_pooling1d_92[0][0]    \n",
            "                                                                 global_max_pooling1d_93[0][0]    \n",
            "                                                                 global_max_pooling1d_94[0][0]    \n",
            "                                                                 global_max_pooling1d_95[0][0]    \n",
            "                                                                 global_max_pooling1d_96[0][0]    \n",
            "                                                                 global_max_pooling1d_97[0][0]    \n",
            "                                                                 global_max_pooling1d_98[0][0]    \n",
            "                                                                 global_max_pooling1d_99[0][0]    \n",
            "                                                                 global_max_pooling1d_100[0][0]   \n",
            "                                                                 global_max_pooling1d_101[0][0]   \n",
            "                                                                 global_max_pooling1d_102[0][0]   \n",
            "                                                                 global_max_pooling1d_103[0][0]   \n",
            "                                                                 global_max_pooling1d_104[0][0]   \n",
            "                                                                 global_max_pooling1d_105[0][0]   \n",
            "                                                                 global_max_pooling1d_106[0][0]   \n",
            "                                                                 global_max_pooling1d_107[0][0]   \n",
            "                                                                 global_max_pooling1d_108[0][0]   \n",
            "                                                                 global_max_pooling1d_109[0][0]   \n",
            "                                                                 global_max_pooling1d_110[0][0]   \n",
            "                                                                 global_max_pooling1d_111[0][0]   \n",
            "                                                                 global_max_pooling1d_112[0][0]   \n",
            "                                                                 global_max_pooling1d_113[0][0]   \n",
            "                                                                 global_max_pooling1d_114[0][0]   \n",
            "                                                                 global_max_pooling1d_115[0][0]   \n",
            "                                                                 global_max_pooling1d_116[0][0]   \n",
            "                                                                 global_max_pooling1d_117[0][0]   \n",
            "                                                                 global_max_pooling1d_118[0][0]   \n",
            "                                                                 global_max_pooling1d_119[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 40)           0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 30)           1230        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            31          dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1)            0           dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 20,029,301\n",
            "Trainable params: 20,029,301\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jQyYbVoU3cv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b4b80d-f2b1-41fb-bb3e-ce30d41043e0"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"models/cnn/cnn-trainable-{epoch:02d}-{val_f1:.2f}.hdf5\", \n",
        "                             monitor='val_f1', save_best_only=True, mode='max', period=1)\n",
        "\n",
        "history_trainable = model.fit(x_train_seq, y_train, batch_size=32, epochs=5, validation_split=0.25, callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/5\n",
            "4198/4198 [==============================] - 1487s 353ms/step - loss: 0.4642 - precision: 0.7734 - recall: 0.7712 - f1: 0.7660 - val_loss: 0.4499 - val_precision: 0.7975 - val_recall: 0.7614 - val_f1: 0.7730\n",
            "Epoch 2/5\n",
            "4198/4198 [==============================] - 1331s 317ms/step - loss: 0.4224 - precision: 0.8013 - recall: 0.7981 - f1: 0.7942 - val_loss: 0.4434 - val_precision: 0.7967 - val_recall: 0.7732 - val_f1: 0.7791\n",
            "Epoch 3/5\n",
            "4198/4198 [==============================] - 1321s 315ms/step - loss: 0.3809 - precision: 0.8309 - recall: 0.8207 - f1: 0.8207 - val_loss: 0.4455 - val_precision: 0.8036 - val_recall: 0.7690 - val_f1: 0.7801\n",
            "Epoch 4/5\n",
            "4198/4198 [==============================] - 1308s 312ms/step - loss: 0.3433 - precision: 0.8548 - recall: 0.8394 - f1: 0.8424 - val_loss: 0.4536 - val_precision: 0.8191 - val_recall: 0.7315 - val_f1: 0.7663\n",
            "Epoch 5/5\n",
            "4198/4198 [==============================] - 1320s 314ms/step - loss: 0.3063 - precision: 0.8769 - recall: 0.8586 - f1: 0.8636 - val_loss: 0.4723 - val_precision: 0.8130 - val_recall: 0.7319 - val_f1: 0.7641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R769zXQFU3cv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "7eb1bf7e-178a-4487-b1bd-3338e23500e3"
      },
      "source": [
        "plot_history(history_trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 4 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfnGHtUVU3cw"
      },
      "source": [
        "model.load_weights('models/cnn/cnn-trainable-03-0.78.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peAjp7O1U3cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8000c5e-3a7b-4ab0-f07d-dd626804db96"
      },
      "source": [
        "predicted = np.round(model.predict(x_test_seq))\n",
        "print(classification_report(y_test, predicted, digits=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.77653   0.81422   0.79493     22457\n",
            "           1    0.80342   0.76417   0.78331     22313\n",
            "\n",
            "    accuracy                        0.78928     44770\n",
            "   macro avg    0.78998   0.78920   0.78912     44770\n",
            "weighted avg    0.78993   0.78928   0.78914     44770\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "0OpzxPHXH_5l",
        "outputId": "837fd08f-1462-4e63-cce8-8f5d59207664"
      },
      "source": [
        "data1 = [\"алексей ну ты алексей здраствуйте\", \"алексей ну ты алексей здраствуйте\", \"алексей ну ты алексей здраствуйте\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(data1)\n",
        "print(data[64457])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-ec440415424a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"алексей ну ты алексей здраствуйте\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"алексей ну ты алексей здраствуйте\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"алексей ну ты алексей здраствуйте\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64457\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocNjRMvfU3cx"
      },
      "source": [
        "## Conclusion\n",
        "This model was evaluated on the test dataset and demonstrated F-measure score up to 78.14%.\n",
        "\n",
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsRSIv9fU3cx"
      },
      "source": [
        "1. Y. Rubtsova, \"Constructing a Corpus for Sentiment Classification Training\", Software & Systems, vol. 109, no. 1, pp. 72-78, 2015.\n",
        "2. T. Mikolov, I. Sutskeve, K. Chen, G. Corrado and J. Dean, \"Distributed Representations of Words and Phrases and their Compositionality\", <i>Advances in Neural Information Processing Systems</i>, vol. 26, pp. 3111-3119, 2013.\n",
        "3. Y. Zhang and B. Wallace, \"A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification\", <i>arXiv preprint arXiv:1510.03820</i>, 2015.\n",
        "4. M. Cliche, \"BB_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs\", <i>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</i>, pp. 573-580, 2017."
      ]
    }
  ]
}